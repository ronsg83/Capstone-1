{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>DATA ACQUISITION</center></h1>\n",
    "\n",
    "Predictive modeling depends crucially on the quality of Data. In the first part of this project, I obtained the latest and most reliable information about more than 6000 films from the Wikipedia page using the Wikipedia API, and also from their IMDB page using the OMDB API. Regular expressions were used to extract budget and box-office information (normmalized to the unit of million dollars). \n",
    "\n",
    "The Wikipedia API was also used to scrape information about The Academy Awards at two levels:\n",
    "1. The different awards and nomination in each of the major categories from 1940 to 2019\n",
    "2. The individual awards and nominations in each category awarded from 1940 to 2019\n",
    "\n",
    "# Contents\n",
    "\n",
    "1. [Obtaining Movie Information using Wikipedia and OMDB API](#movieinfo)\n",
    "2. [Data Acquisition](#data_acquisition)<br>\n",
    "   i) [Web scraping](#scrape)<br>\n",
    "   ii) [Challenges and Fixes](#challenges) <br>\n",
    "   iii) [Creating Movies DataFrame](#dataframe)\n",
    "3. [Obtaining Academy Award Information](#academy)<br>\n",
    "   i) [For Films](#films)<br>\n",
    "   ii) [For Individuals](#individuals)<br>\n",
    "\n",
    "\n",
    "This project aims to analyze movie data from IMDB database based on 3 categories (commercial, critical and financial) and predict the nominees and winners for the The 92<sup>nd</sup> Academy Awards due to be held in 2020. \n",
    "\n",
    "The Data Acquisition phase will comprise of 3 steps:\n",
    "1. To obtain a list of English language films betwen the year 1955 to 2019\n",
    "2. To obtain the complete list of Academy Award winners and nominees, both in the film and individual categories\n",
    "\n",
    "By acquiring the latest and most updated data about films from **Wikipedia** and **IMDB** website of Hollywood films from 1940 to 2019, we will attempt to identify the key features that make films successful, popular and enduring. \n",
    "\n",
    "We will look at three key parameters:\n",
    "1. Accolades given by The Academy of Motion Pictures\n",
    "2. Box office revenues\n",
    "3. IMDB ratings based on fan reviews\n",
    "\n",
    "Based on these outcomes, we will explore the history of hollywood films and The Academy Awards to see what makes movies resonate with fans and endure over time. Why do some films become commercially successful but fail to win critical acclaim? Is there a correlation between budget and box-office revenues - do big budget moviesd make more money? Is there any significant correlation between how fans and the Academy view a film's success? \n",
    "\n",
    "By pooling data from various sources, defining metrics and measures that are simple and intuitive, we will try to uncover the secrets of great films. Using this knoweldge and information, we will try to predict the nominees and winners for the upcoming Oscars due to be held in 2020. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import wikipedia\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "from scrapy import selector\n",
    "import datetime as dt\n",
    "import pickle\n",
    "from skimage import io\n",
    "from IPython.display import clear_output\n",
    "import pdb\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"movie_info\"></a>\n",
    "# 1.0 Obtaining Movie List and Creating Initial Database\n",
    "\n",
    "For the project of analyzing movie success and predicting the Academy Award winner for the year 2020, our first step was to obtain a list of all major English films made between the years 1950 to 2019. In order to do that, we looked at the List of American abd British films made in each year in that period. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the 1960's\n",
      "In the 1970's\n",
      "In the 1980's\n",
      "In the 1990's\n",
      "In the 2000's\n",
      "In the 2010's\n",
      "CPU times: user 23.5 s, sys: 614 ms, total: 24.1 s\n",
      "Wall time: 3min 18s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17776"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "primary_list = []\n",
    "for year in range(1960,2020):\n",
    "    if year%10==0:\n",
    "        print(f\"In the {year}'s\")\n",
    "    # Set URL\n",
    "    my_url = ['List_of_American_films_of_'+ str(year), 'List_of_British_films_of_'+ str(year)]\n",
    "    \n",
    "    #Define empty list for the year\n",
    "    \n",
    "    for url in my_url:\n",
    "        page = wikipedia.page(url)\n",
    "        soup = BeautifulSoup(page.html(),'lxml')\n",
    "        tables = soup.find_all('table', class_ = 'wikitable') # , class_=\"wikitable sortable jquer-tablesorter\")\n",
    "        movie_set_us = []\n",
    "        for table in tables:\n",
    "            films = table.find_all('i')\n",
    "            for film in films:\n",
    "                title = film.text\n",
    "                # print(title)\n",
    "                link = film.find_all('a', href=True, title = True)\n",
    "                if len(link)==0:\n",
    "                    continue\n",
    "                else:\n",
    "                    link = link[0]['href']\n",
    "                primary_list.append((year,film.text.lower()))\n",
    "\n",
    "        \n",
    "pickle.dump(primary_list,open('my_data_4/PRIMARY_LIST_1960_2019', \"wb\" ))\n",
    "len(primary_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "##########GET ALL ##########\n",
    "movie_dict_ALL = dict()\n",
    "for i,(year, title) in enumerate(primary_list):\n",
    "    if i%21 == 0:\n",
    "        clear_output()\n",
    "    movie_dict_ALL[(title,year)] = get_all_movie_info(title, year)\n",
    "    pickle.dump(movie_dict_ALL,open( 'my_data_4/movie_dict_ALL', \"wb\" ))\n",
    "        \n",
    "\n",
    "#SAVE movie_dict\n",
    "print(len(movie_dict_ALL))\n",
    "pickle.dump(movie_dict_2019,open( 'my_data_4/movie_dict_ALL', \"wb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"scrape\"></a>\n",
    "# The Wikipedia API\n",
    "\n",
    "The API consists of a collection of functions for standardizing budget (to US million dollars) and prediceded genres so that final Dataframes are all consistent.\n",
    "\n",
    "The following functions are defined below:\n",
    "1. wikiapi_film(title, year): returns **intro** and **infobox** HTML from wikipedia page\n",
    "2. get_genre(intro): Scrapes the intro paragraph of the wikipedia page and identifies genres\n",
    "3. movie_info_dict(infobox): returns dictionary with all the information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WIKIPEDIA API Function: Returns page for specified film and year\n",
    "def wikiapi_film(title, year):   \n",
    "    '''Takes in a title, award and year, and returns the the wikipedia.page containing HTML\n",
    "    ''' \n",
    "    if len(title)==0 or len(str(year)) == 0:\n",
    "        return \n",
    "    \n",
    "    try:\n",
    "        if wikipedia.page(title)!=None:\n",
    "            print(title)\n",
    "            return wikipedia.page(title)\n",
    "    except wikipedia.exceptions.DisambiguationError:\n",
    "        pass\n",
    "    except wikipedia.exceptions.PageError:\n",
    "        pass\n",
    "\n",
    "    title_without_date = title + ' (film)'\n",
    "    try:\n",
    "        if wikipedia.page(title_without_date) != None:\n",
    "            print(title_without_date)\n",
    "            return wikipedia.page(title_without_date)            \n",
    "   \n",
    "    except wikipedia.exceptions.DisambiguationError:\n",
    "        print(f\"\\tCould not fetch information for {title}: Disambiguation error\")\n",
    "        return\n",
    "    except wikipedia.exceptions.PageError:\n",
    "        print(f\"\\tThe Wikipedia page for the title {title} could not be found: Page Error \")\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rom': 'romance',\n",
       " 'com': 'comedy',\n",
       " 'mus': 'musical',\n",
       " 'ani': 'animated',\n",
       " 'sup': 'superhero',\n",
       " 'hor': 'horror',\n",
       " 'cri': 'crime',\n",
       " 'war': 'war ',\n",
       " 'psy': 'psychological',\n",
       " 'act': 'action',\n",
       " 'dys': 'dystopian',\n",
       " 'pol': 'political',\n",
       " 'spy': 'spy',\n",
       " 'sci': 'sci-fi',\n",
       " 'adv': 'adventure',\n",
       " 'fan': 'fantasy',\n",
       " 'bio': 'biographical',\n",
       " 'his': 'historical',\n",
       " 'mys': 'mystery',\n",
       " 'epi': 'epic',\n",
       " 'thr': 'thrill',\n",
       " 'dra': 'drama',\n",
       " 'mon': 'monster',\n",
       " 'dis': 'disaster',\n",
       " 'oth': 'other',\n",
       " 'other': 'other'}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the standardized genre specified in genre_dict file\n",
    "genre_dict = {\n",
    "        'romance': 'rom',\n",
    "        'romantic': 'rom',\n",
    "        'comedy': 'com',\n",
    "        'musical':'mus',\n",
    "        'animated':'ani',\n",
    "        'superhero':'sup',\n",
    "        'horror':'hor',\n",
    "        'crime': 'cri',\n",
    "        'war ':'war',\n",
    "        'psychological':'psy',\n",
    "        'psychology':'psy',\n",
    "        'action':'act',\n",
    "        'dystopian':'dys',\n",
    "        'political':'pol',\n",
    "        'spy':'spy',\n",
    "        'science': 'sci',\n",
    "        'sci-fi': 'sci',\n",
    "        'adventure':'adv',\n",
    "        'fantasy': 'fan',\n",
    "        'biography': 'bio',\n",
    "        'biographical': 'bio',\n",
    "        'historical':'his',\n",
    "        'mystery':'mys',\n",
    "        'epic':'epi',\n",
    "        'thrill':'thr',\n",
    "        'drama':'dra',\n",
    "        'monster': 'mon',\n",
    "        'disaster':'dis',\n",
    "        'other':'oth'\n",
    "    }\n",
    "pickle.dump(genre_dict,open( 'my_data_4/genre_dict', \"wb\" ))\n",
    "\n",
    "del genre_dict['psychology']\n",
    "del genre_dict['romantic']\n",
    "del genre_dict['biography']\n",
    "del genre_dict['science']\n",
    "\n",
    "genre_dict2 = {}\n",
    "for key,value in genre_dict.items():\n",
    "    genre_dict2[value]= key\n",
    "genre_dict2['other'] = 'other'\n",
    "pickle.dump(genre_dict2,open( 'my_data_4/genre_dict2', \"wb\" ))\n",
    "genre_dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genre(intro):\n",
    "    \"\"\"returns the movie genre based on wikipedia intro, returns list of genres\n",
    "    \"\"\"\n",
    "    genre_dict = pickle.load(open(\"my_data_4/genre_dict\",\"rb\"))\n",
    "    this_movie_genres = []\n",
    "    for line in intro: # got through all the lines\n",
    "        line = line.text.split('.')\n",
    "        line = line[0]\n",
    "        line = line.lower()\n",
    "        for genre in genre_dict:\n",
    "            if line.find(genre) > 0:\n",
    "                this_movie_genres.append(genre_dict[genre])\n",
    "        \n",
    "        if len(this_movie_genres)>0:\n",
    "            return list(set(this_movie_genres))\n",
    "    return ['other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary from Wikipedia page of the film using the INFOBOX table\n",
    "\n",
    "def movie_infobox_dict(infobox_items, intro, title, year):\n",
    "    \"\"\"Accepts an infobox item and intro sections of wikipedia page and returns a dictionary\n",
    "    \"\"\"\n",
    "    # initialiZe empty dictionary\n",
    "    _movie_dict = dict()\n",
    "    \n",
    "    # Go through each infobox item and extract information\n",
    "    for item in infobox_items:\n",
    "        try:\n",
    "            if len(item) < 2:\n",
    "                continue\n",
    "            \n",
    "            #director\n",
    "            if item.th.text.lower().find('direct')>-1:\n",
    "                _movie_dict['director'] = []\n",
    "                if item.td.find('div', class_=\"plainlist\")==None: # single entries\n",
    "                    for line in item.td.find_all('a'):\n",
    "                        _movie_dict['director'].append(line.text)      \n",
    "                else:\n",
    "                    for line in item.td.find('div', class_=\"plainlist\").find_all('li'):\n",
    "                        _movie_dict['director'].append(line.text)\n",
    "                if len(_movie_dict['director'])==0:\n",
    "                    _movie_dict['director'] = item.td.text.split('br')\n",
    "            #producer\n",
    "            if item.th.text.lower().find('produce')>-1:\n",
    "                _movie_dict['producer'] = []\n",
    "                if item.td.find('div', class_=\"plainlist\")==None: # single entries\n",
    "                    for line in item.td.find_all('a'):\n",
    "                        _movie_dict['producer'].append(line.text)    \n",
    "                else:\n",
    "                    for line in item.td.find('div', class_=\"plainlist\").find_all('li'):\n",
    "                        _movie_dict['producer'].append(line.text) \n",
    "                if len(_movie_dict['producer'])==0:\n",
    "                    _movie_dict['producer'] = item.td.text.split('br')\n",
    "\n",
    "            #cast\n",
    "            if item.th.text.lower().find('star')>-1:\n",
    "                _movie_dict['cast'] = []\n",
    "                if item.td.find('div', class_=\"plainlist\")==None: # single entries\n",
    "                    for line in item.td.find_all('a'):\n",
    "                        _movie_dict['cast'].append(line.text)\n",
    "                else:\n",
    "                    for line in item.td.find('div', class_=\"plainlist\").find_all('li'):\n",
    "                        _movie_dict['cast'].append(line.text)\n",
    "                if len(_movie_dict['cast'])==0:\n",
    "                    _movie_dict['cast'] = item.td.text.split('br')\n",
    "\n",
    "            #screenplay\n",
    "            if item.th.text.lower().find('screenplay')>-1 or item.th.text.lower().find('written')>-1:\n",
    "                _movie_dict['screenplay'] = []\n",
    "                if item.td.find('div', class_=\"plainlist\")==None: # single entries\n",
    "                    for line in item.td.find_all('a'):\n",
    "                        _movie_dict['screenplay'].append(line.text)\n",
    "                else:\n",
    "                    for line in item.td.find('div', class_=\"plainlist\").find_all('li'):\n",
    "                        _movie_dict['screenplay'].append(line.text)\n",
    "                if len(_movie_dict['screenplay'])==0:\n",
    "                    _movie_dict['screenplay'] = item.td.text.split('br')\n",
    "\n",
    "            #cinematography\n",
    "            if item.th.text.lower().find('cinematography')>-1:\n",
    "                _movie_dict['cinematography'] = []\n",
    "                if item.td.find('div', class_=\"plainlist\")==None: # single entries\n",
    "                    for line in item.td.find_all('a'):\n",
    "                        _movie_dict['cinematography'].append(line.text)\n",
    "                else:\n",
    "                    for line in item.td.find('div', class_=\"plainlist\").find_all('li'):\n",
    "                        _movie_dict['cinematography'].append(line.text)\n",
    "                if len(_movie_dict['cinematography'])==0:\n",
    "                    _movie_dict['cinematography'] = item.td.text.split('br')\n",
    "\n",
    "            # music\n",
    "            if item.th.text.lower().find('music')>-1 or item.th.text.lower().find('score')>-1:\n",
    "                _movie_dict['music'] = []\n",
    "                if item.td.find('div', class_=\"plainlist\")==None: # single entries\n",
    "                    for line in item.td.find_all('a'):\n",
    "                        _movie_dict['music'].append(line.text)\n",
    "                else:\n",
    "                    for line in item.td.find('div', class_=\"plainlist\").find_all('li'):\n",
    "                        _movie_dict['music'].append(line.text)\n",
    "                if len(_movie_dict['music'])==0:\n",
    "                    _movie_dict['music'] = item.td.text\n",
    "                \n",
    "            # editing\n",
    "            if item.th.text.lower().find('edit')>-1:\n",
    "                _movie_dict['edit'] = []\n",
    "                if item.td.find('div', class_=\"plainlist\")==None: # single entries\n",
    "                    for line in item.td.find_all('a'):\n",
    "                        _movie_dict['edit'].append(line.text)\n",
    "                else:\n",
    "                    for line in item.td.find('div', class_=\"plainlist\").find_all('li'):\n",
    "                        _movie_dict['edit'].append(line.text)\n",
    "                if len(_movie_dict['edit'])==0:\n",
    "                    _movie_dict['edit'] = item.td.text.split('br')\n",
    "\n",
    "            # Based on a book (Y/N)\n",
    "            if item.th.text.lower().find('based')>-1:\n",
    "                _movie_dict['book'] = 'yes'\n",
    "\n",
    "            # Get budget\n",
    "            if item.th.text.lower().find('budget')>-1:\n",
    "                budget = item.td.text.strip()\n",
    "                budget = re.sub(r'\\[.+\\]+', \"\", budget) #remove square bracket references\n",
    "                _movie_dict['budget'] = currency_to_million(budget)\n",
    "\n",
    "            # Get box office\n",
    "            if item.th.text.lower().find('box')>-1:\n",
    "                box_office = item.td.text.strip()\n",
    "                box_office = re.sub(r'\\[.+\\]+', \"\", box_office)#remove square bracket references\n",
    "                _movie_dict['box_office'] = currency_to_million(box_office)\n",
    "\n",
    "            # Get running time\n",
    "            if item.th.text.lower().find('running time')>-1:\n",
    "                running_time = item.td.text.strip()\n",
    "                running_time = re.findall(r'(\\d+)\\smin', running_time)\n",
    "                if len(running_time)==0:\n",
    "                    _movie_dict['running_time'] = 0\n",
    "                    continue\n",
    "                _movie_dict['running_time'] = int(running_time[0])\n",
    "\n",
    "            # Language \n",
    "            if item.th.text.lower().find('language')>-1:\n",
    "                language = item.td.text.strip()\n",
    "                if (language.lower().find('english') == -1 and \n",
    "                    language.lower().find('silent') == -1): # film does not contain english\n",
    "                    return dict()\n",
    "                _movie_dict['language']= language.split('\\n')\n",
    "\n",
    "            # Release date \n",
    "            if item.th.text.lower().find('release')>-1:\n",
    "                release = item.td.text.strip()\n",
    "                release = re.findall(r'\\d\\d\\d\\d', release)\n",
    "                if len(release)==0:\n",
    "                    print(f'Year not found for {title} in {year}')\n",
    "                    return dict()\n",
    "                release = dt.datetime.strptime(release[0], '%Y').year\n",
    "#                 if release !=year: # or len(str(release))==0:\n",
    "#                     print(f'Wrong year for {title}! Corrected to wikipedia year')\n",
    "#                     return dict()\n",
    "#                     # _movie_dict['year']= year\n",
    "#                 else:\n",
    "                _movie_dict['year']=release\n",
    "            \n",
    "            \n",
    "            # Get genre\n",
    "            _movie_dict['genre'] = get_genre(intro)\n",
    "\n",
    "        except AttributeError:\n",
    "            print(f'\\tCould not fetch info for {title} from infobox items')\n",
    "\n",
    "    return _movie_dict\n",
    "\n",
    "\n",
    "# Converts different denominations to $X.y million\n",
    "def currency_to_million(money):\n",
    "    ''' Accepts $12 million and returns 12000000\n",
    "        Accepts $13,678,654 and reurns  13678654\n",
    "        Accept $15-25 million and returns 25000000\n",
    "        Accepts $2 billion and returns 2000000000\n",
    "        using regular expressions\n",
    "    '''\n",
    "    if money == None:\n",
    "        return np.nan\n",
    "    if len(money)==0:\n",
    "        return np.nan\n",
    "\n",
    "    # Check to see dollar, otherwise return nan\n",
    "    money = money.lower()\n",
    "    if money.find('$')>-1:\n",
    "        factor=1\n",
    "    elif money.find('£')>-1:\n",
    "        factor = 1.3\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "    money = re.sub(r'\\[.*\\]', '', money) #remove square bracket citation\n",
    "\n",
    "    if money.find('illion')>0: # when currency expressed in million/billion\n",
    "\n",
    "        # Billion: $12.4 billion\n",
    "        reg = r\"[\\$-–]([0-9.]+)\\sbillion\"\n",
    "        num = re.findall(reg, money) # find number like $12.4 billion\n",
    "        if len(num)>0:\n",
    "            # num = re.sub(r'\\D', \"\", num) # drop any non-numeric characters like comma, dash etc\n",
    "            return  round(float(num[0])*1e3*factor,2)\n",
    "\n",
    "        # Million: $6.8 million\n",
    "        reg = r\"[\\$-–]([0-9.]+)\\smillion\"\n",
    "        num = re.findall(reg, money) # find number like $6.8 million\n",
    "        if len(num)>0:\n",
    "            # num = re.sub(r'\\D', \"\", num) # drop any non-numeric characters like comma, dash etc\n",
    "            try:\n",
    "                return round(float(num[0])*factor,2)\n",
    "            except:\n",
    "                return np.nan\n",
    "\n",
    "    else: # When currency not expressed in millions  \n",
    "        reg = r\"[$£]\\s?([\\d,]+)[\\D\\s]?\"\n",
    "        num = re.findall(reg, money)\n",
    "        if len(num) >0:\n",
    "            num = re.sub(r',', '', num[0])\n",
    "            try:\n",
    "                return round(float(num)/1e6*factor,2)\n",
    "            except:\n",
    "                return np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# title = 'annie hall'\n",
    "# year = 1977\n",
    "# page = wikiapi_film(title, year)\n",
    "# soup = BeautifulSoup(page.html(),'lxml') \n",
    "# infobox_items = soup.find('table', class_ = 'infobox vevent').tbody.find_all('tr')\n",
    "# infobox_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the main function that calls wikiapi_film, OMDB API and ancillary functions to get the dictionaries\n",
    "def get_all_movie_info(title, year, skip_imdb = 0):\n",
    "    \"\"\"This is the MAIN function that uses previous functions to accept title and year and return \n",
    "    all the movie information, returns dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    # Wikipedia info\n",
    "    page = wikiapi_film(title, year)\n",
    "    if page == None:\n",
    "        return dict()\n",
    "\n",
    "    soup = BeautifulSoup(page.html(),'lxml') \n",
    "    \n",
    "    # Get wikipedia introduction paragraph for genres\n",
    "    try:\n",
    "        intro = soup.find_all('p')\n",
    "    except:\n",
    "        print(f'Could not find p-tags info for {title}')\n",
    "        return dict()\n",
    "    \n",
    "    # Get wikipedia infobox tables for all other information\n",
    "    try:\n",
    "        infobox_items = soup.find('table', class_ = 'infobox vevent').tbody.find_all('tr')\n",
    "    except: \n",
    "        print(f'Could not find infobox for {title}')\n",
    "        return dict()\n",
    "        \n",
    "    this_dict = movie_infobox_dict(infobox_items, intro, title, year) # get movie info dictionary\n",
    "    if len(this_dict) == 0:\n",
    "        print(f'Wikipedia could not get {title} in {year}')\n",
    "        return dict()\n",
    "    # return this_dict\n",
    "\n",
    "    # obtain json file from OMDB API and get info\n",
    "    url_base = 'http://www.omdbapi.com/?i=tt3896198&apikey=5db77b44&'\n",
    "    url = url_base + 't=' + str(title)\n",
    "    r = requests.get(url)\n",
    "    json_data = r.json()\n",
    "    if 'Error' in json_data:\n",
    "        print(f'\\t{title} not found in OMDB API')\n",
    "        return dict()\n",
    "    if skip_imdb == 1:\n",
    "        return this_dict\n",
    "    else:\n",
    "        try:\n",
    "            this_dict['imdbID'] = json_data['imdbID']\n",
    "            this_dict['imdb_rating'] = float(json_data['imdbRating'])\n",
    "            this_dict['n_votes'] = int(re.sub(r',','',json_data['imdbVotes']))\n",
    "            this_dict['title'] =title\n",
    "            return this_dict\n",
    "        except:\n",
    "            print(f'Unknown error in {title}: could not fetch info')\n",
    "            return dict()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Movie Information from 1950 to 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.13 s, sys: 413 ms, total: 2.54 s\n",
      "Wall time: 10.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Get movie_dict from df_imdb list and SAVE. df_imdb was created in an older version of the \n",
    "df_imdb = pd.read_csv('my_data_4/df_imdb.csv')\n",
    "movie_dict = pickle.load(open(\"my_data_4/movie_dict\",\"rb\"))\n",
    "year_start = 1950\n",
    "year_stop = 2018\n",
    "years = range(year_start,year_stop+1)\n",
    "df_imdb.reset_index(inplace=True, drop=True)\n",
    "for row in df_imdb.iterrows():\n",
    "    \n",
    "    if row[0]%20==0: # prevent clutter, clear output after every 20 movies\n",
    "        clear_output()\n",
    "        \n",
    "    idx = row[0]\n",
    "    title = row[1].title.lower()\n",
    "    year = row[1].year\n",
    "    \n",
    "    \n",
    "    if year not in years:\n",
    "        continue\n",
    "    \n",
    "    # Get information and save in movie_dict\n",
    "    if(title, year) not in movie_dict:\n",
    "        movie_dict[(title,year)] = get_all_movie_info(title, year)\n",
    "    if row[0]%20==0:\n",
    "        clear_output()\n",
    "\n",
    "#Save dictionary       \n",
    "pickle.dump(movie_dict,open( 'my_data_4/movie_dict_new2', \"wb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get 2019 Movie Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "star wars: the rise of skywalker\n",
      "Unknown error in star wars: the rise of skywalker: could not fetch info\n",
      "alita: battle angel\n",
      "tyler perry's a madea family funeral\n",
      "\ttyler perry's a madea family funeral not found in OMDB API\n",
      "buffaloed\n",
      "Unknown error in buffaloed: could not fetch info\n",
      "darlin' (film)\n",
      "Could not find infobox for darlin'\n",
      "monos\n",
      "Wikipedia could not get monos in 2019\n",
      "star wars: the rise of skywalker\n",
      "Unknown error in star wars: the rise of skywalker: could not fetch info\n",
      "mr. jones\n",
      "\tmr. jones not found in OMDB API\n",
      "for sama\n",
      "Wikipedia could not get for sama in 2019\n",
      "nomad: in the footsteps of bruce chatwin\n",
      "Unknown error in nomad: in the footsteps of bruce chatwin: could not fetch info\n",
      "first love\n",
      "Wikipedia could not get first love in 2019\n",
      "balance, not symmetry\n",
      "Unknown error in balance, not symmetry: could not fetch info\n",
      "carmilla\n",
      "Could not find infobox for carmilla\n",
      "carmilla\n",
      "Could not find infobox for carmilla\n",
      "shooting clerks\n",
      "Year not found for shooting clerks in 2019\n",
      "Wikipedia could not get shooting clerks in 2019\n",
      "bombay rose\n",
      "Wikipedia could not get bombay rose in 2019\n",
      "coup 53\n",
      "Unknown error in coup 53: could not fetch info\n",
      "the retreat from moscow\n",
      "Unknown error in the retreat from moscow: could not fetch info\n",
      "sweetness in the belly\n",
      "Unknown error in sweetness in the belly: could not fetch info\n",
      "true history of the kelly gang\n",
      "Could not find infobox for true history of the kelly gang\n",
      "true history of the kelly gang\n",
      "Could not find infobox for true history of the kelly gang\n",
      "eternal beauty\n",
      "Unknown error in eternal beauty: could not fetch info\n",
      "fanny lye deliver'd\n",
      "Unknown error in fanny lye deliver'd: could not fetch info\n",
      "he dreams of giants\n",
      "Unknown error in he dreams of giants: could not fetch info\n",
      "blue story\n",
      "old possum's book of practical cats\n",
      "Could not find infobox for old possum's book of practical cats\n",
      "henry iv, part 1\n",
      "Could not find infobox for henry iv, part 1\n",
      "henry iv, part 2\n",
      "Could not find infobox for henry iv, part 2\n",
      "the surgeon of crowthorne\n",
      "Could not find infobox for the surgeon of crowthorne\n",
      "CPU times: user 3.73 s, sys: 215 ms, total: 3.95 s\n",
      "Wall time: 58.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "##########GET 2019 moives ##########\n",
    "movie_dict_2019 = pickle.load(open(\"my_data_4/movie_dict_2019\",\"rb\"))\n",
    "\n",
    "movies_all = pickle.load(open('my_data_4/PRIMARY_LIST_1960_2019', \"rb\" ))\n",
    "skip_imdb = 0\n",
    "for (year, title) in movies_all:\n",
    "    if year!=2019:\n",
    "        continue\n",
    "    if (title,year) not in movie_dict_2019 or len(movie_dict_2019[(title,year)])==0:\n",
    "        movie_dict_2019[(title,year)] = get_all_movie_info(title, year)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Imputations\n",
    "\n",
    "For 2 of the movies in 2019, \"Uncut Gems\" and \"Once upon a time in hollywood\", the IMDB information appeared to be corrupted. Therefore, these information was added manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling in information for uncut gems\n",
    "movie_dict_2019 = pickle.load(open(\"my_data_4/movie_dict_2019\",\"rb\"))\n",
    "title = 'uncut gems'\n",
    "year = 2019\n",
    "movie_dict_2019[(title, year)]['imdbID'] = 'tt5727208'\n",
    "movie_dict_2019[(title, year)]['imdb_rating'] = 8.1\n",
    "movie_dict_2019[(title, year)]['n_votes'] = 12969\n",
    "movie_dict_2019[(title, year)]['title']=title\n",
    "movie_dict_2019[(title, year)]\n",
    "\n",
    "title = 'once upon a time in hollywood'\n",
    "year = 2019\n",
    "movie_dict_2019[(title, year)]['imdbID'] = 'tt7131622'\n",
    "movie_dict_2019[(title, year)]['imdb_rating'] = 7.8\n",
    "movie_dict_2019[(title, year)]['n_votes'] = 303486\n",
    "movie_dict_2019[(title, year)]['title']=title\n",
    "# movie_dict_2019[(title, year)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(movie_dict_2019,open( 'my_data_4/movie_dict_2019', \"wb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"dataframe\"></a>\n",
    "## Create DataFrame from movie_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe_from_dict2(movie_dict, all_columns, years):\n",
    "    \"\"\"Accept the movie_info_dict and creates the DataFrame \n",
    "    containing budget, box_office, running_time, cast etc (mentioned in columns)\n",
    "    Returns a dataframe\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(columns = all_columns)\n",
    "    rejects = []\n",
    "    for i,(title,year) in enumerate(movie_dict):\n",
    "\n",
    "        \n",
    "        #Tracking display\n",
    "        if i%20 == 0:\n",
    "            clear_output()\n",
    "\n",
    "        print(title,year)\n",
    "        movie = movie_dict[title,year]\n",
    "        if len(movie)==0:\n",
    "            print(f'\\tCould not prepare DataFrame for {title}. Movie info missing!')\n",
    "            rejects.append((title,year))\n",
    "\n",
    "            continue\n",
    "        if 'year' not in movie:\n",
    "            movie['year']=year\n",
    "\n",
    "        if movie['year'] != year or movie['year'] not in years: # the year information is incorrect\n",
    "            print(title, year)\n",
    "            print('Broken!')\n",
    "            rejects.append((title,year))\n",
    "            continue\n",
    "\n",
    "        if movie['imdbID'] in df.imdbID:\n",
    "            print(f'{title} duplicated: Skipping')\n",
    "\n",
    "        for col in all_columns:\n",
    "            # print(i,title)\n",
    "            if col in movie:\n",
    "                if type(movie[col])!=list:\n",
    "                    df.loc[i,col] = movie[col]\n",
    "                elif type(movie[col])==list:\n",
    "                    df.loc[i,col] = len(movie[col])\n",
    "            else:\n",
    "                rejects.append((title,year))\n",
    "\n",
    "                \n",
    "    return df, list(set(rejects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mr. turner 2014\n",
      "\tCould not prepare DataFrame for mr. turner. Movie info missing!\n",
      "begin again 2014\n",
      "ida 2014\n",
      "ex machina 2015\n",
      "cinderella 2015\n",
      "the lobster 2016\n",
      "passengers 2016\n",
      "13 hours: the secret soldiers of benghazi 2016\n",
      "\tCould not prepare DataFrame for 13 hours: the secret soldiers of benghazi. Movie info missing!\n",
      "star wars: the last jedi 2017\n",
      "victoria & abdul 2017\n",
      "roma 2018\n",
      "at eternity's gate 2018\n",
      "the wife 2018\n",
      "first reformed 2018\n",
      "the ballad of buster scruggs 2018\n",
      "isle of dogs 2018\n",
      "never look away 2018\n",
      "(6148, 10)\n",
      "after dropna() (5867, 10)\n",
      "Done!\n",
      "CPU times: user 1min 36s, sys: 3.84 s, total: 1min 40s\n",
      "Wall time: 1min 38s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdbID</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>n_votes</th>\n",
       "      <th>imdb_rating</th>\n",
       "      <th>budget</th>\n",
       "      <th>box_office</th>\n",
       "      <th>cast</th>\n",
       "      <th>genre</th>\n",
       "      <th>running_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>tt0097626</td>\n",
       "      <td>johnny handsome</td>\n",
       "      <td>1989</td>\n",
       "      <td>8324</td>\n",
       "      <td>6.2</td>\n",
       "      <td>20</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>tt0092997</td>\n",
       "      <td>extreme prejudice</td>\n",
       "      <td>1987</td>\n",
       "      <td>5649</td>\n",
       "      <td>6.7</td>\n",
       "      <td>22</td>\n",
       "      <td>1.13078e+06</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>tt0076759</td>\n",
       "      <td>star wars: episode iv - a new hope</td>\n",
       "      <td>1977</td>\n",
       "      <td>1150440</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1308</td>\n",
       "      <td>9323</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>tt0120903</td>\n",
       "      <td>x-men</td>\n",
       "      <td>2000</td>\n",
       "      <td>545484</td>\n",
       "      <td>7.4</td>\n",
       "      <td>75</td>\n",
       "      <td>296.3</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>tt0118200</td>\n",
       "      <td>x</td>\n",
       "      <td>2011</td>\n",
       "      <td>2395</td>\n",
       "      <td>6.2</td>\n",
       "      <td>1670</td>\n",
       "      <td>6020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      imdbID                               title  year  n_votes imdb_rating  \\\n",
       "0  tt0097626                     johnny handsome  1989     8324         6.2   \n",
       "1  tt0092997                   extreme prejudice  1987     5649         6.7   \n",
       "2  tt0076759  star wars: episode iv - a new hope  1977  1150440         8.6   \n",
       "3  tt0120903                               x-men  2000   545484         7.4   \n",
       "4  tt0118200                                   x  2011     2395         6.2   \n",
       "\n",
       "  budget   box_office cast genre running_time  \n",
       "0     20         7.24    7     3           96  \n",
       "1     22  1.13078e+06    3     3          104  \n",
       "2   1308         9323  NaN     4          NaN  \n",
       "3     75        296.3   10     4          104  \n",
       "4   1670         6020  NaN     3          NaN  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Create DataFrame up to year 2018 and SAVE as df_movies\n",
    "movie_dict = pickle.load(open(\"my_data_4/movie_dict\",\"rb\"))\n",
    "columns = ['imdbID','title','year','n_votes','imdb_rating','budget', 'box_office','cast', 'genre','running_time']\n",
    "df_movies, rejected = create_dataframe_from_dict2(movie_dict, columns, range(1950,2019))\n",
    "print(df_movies.shape)\n",
    "df_movies = df_movies[df_movies.imdbID.duplicated() == False]\n",
    "print('after dropna()',df_movies.shape)\n",
    "print('Done!')\n",
    "\n",
    "# Convert year column from integer to date_time and SAVE\n",
    "df_movies.year = [y.year for y in pd.to_datetime(df_movies.year.astype('int'), format='%Y')]\n",
    "df_movies.reset_index(drop=True)\n",
    "df_movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjusting for Inflation\n",
    "Inflation chart obtained from https://www.usinflationcalculator.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5867, 13)\n"
     ]
    }
   ],
   "source": [
    "# DF_MOVIES\n",
    "# df_movies = pd.read_csv('my_data_4/df_movies.csv')\n",
    "cpi = pd.read_csv('my_data_4/CPI_index.csv')\n",
    "cpi.rename({'Year':'year'}, axis = 1,inplace=True)\n",
    "cpi.set_index('year', inplace=True)\n",
    "cpi.loc[2019,'Avg']=255.0 # 2019 information was missing and entered manually\n",
    "\n",
    "cpi = cpi[['Avg']]\n",
    "cpi['factor'] = 1/(cpi.Avg/100)\n",
    "cpi.tail()\n",
    "\n",
    "# Create new DataFrame adjusting for inflation\n",
    "df_budget = df_movies[['year', 'budget']]                  \n",
    "df_movies['inflation_factor'] = [cpi.loc[x,'factor'] for x in df_movies.year]\n",
    "df_movies['budget_adjusted'] = df_movies['budget']*df_movies['inflation_factor']\n",
    "df_movies['box_office_adjusted'] = df_movies['box_office']*df_movies['inflation_factor']\n",
    "\n",
    "print(df_movies.shape)\n",
    "df_movies.to_csv('my_data_4/df_movies_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdbID</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>n_votes</th>\n",
       "      <th>imdb_rating</th>\n",
       "      <th>budget</th>\n",
       "      <th>box_office</th>\n",
       "      <th>cast</th>\n",
       "      <th>genre</th>\n",
       "      <th>running_time</th>\n",
       "      <th>inflation_factor</th>\n",
       "      <th>budget_adjusted</th>\n",
       "      <th>box_office_adjusted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>tt0097626</td>\n",
       "      <td>johnny handsome</td>\n",
       "      <td>1989</td>\n",
       "      <td>8324</td>\n",
       "      <td>6.2</td>\n",
       "      <td>20</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>96</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>16.129</td>\n",
       "      <td>5.83871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>tt0092997</td>\n",
       "      <td>extreme prejudice</td>\n",
       "      <td>1987</td>\n",
       "      <td>5649</td>\n",
       "      <td>6.7</td>\n",
       "      <td>22</td>\n",
       "      <td>1.13078e+06</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>104</td>\n",
       "      <td>0.880282</td>\n",
       "      <td>19.3662</td>\n",
       "      <td>995409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>tt0076759</td>\n",
       "      <td>star wars: episode iv - a new hope</td>\n",
       "      <td>1977</td>\n",
       "      <td>1150440</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1308</td>\n",
       "      <td>9323</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.650165</td>\n",
       "      <td>2158.42</td>\n",
       "      <td>15384.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>tt0120903</td>\n",
       "      <td>x-men</td>\n",
       "      <td>2000</td>\n",
       "      <td>545484</td>\n",
       "      <td>7.4</td>\n",
       "      <td>75</td>\n",
       "      <td>296.3</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>104</td>\n",
       "      <td>0.580720</td>\n",
       "      <td>43.554</td>\n",
       "      <td>172.067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>tt0118200</td>\n",
       "      <td>x</td>\n",
       "      <td>2011</td>\n",
       "      <td>2395</td>\n",
       "      <td>6.2</td>\n",
       "      <td>1670</td>\n",
       "      <td>6020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.444565</td>\n",
       "      <td>742.424</td>\n",
       "      <td>2676.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      imdbID                               title  year  n_votes imdb_rating  \\\n",
       "0  tt0097626                     johnny handsome  1989     8324         6.2   \n",
       "1  tt0092997                   extreme prejudice  1987     5649         6.7   \n",
       "2  tt0076759  star wars: episode iv - a new hope  1977  1150440         8.6   \n",
       "3  tt0120903                               x-men  2000   545484         7.4   \n",
       "4  tt0118200                                   x  2011     2395         6.2   \n",
       "\n",
       "  budget   box_office cast genre running_time  inflation_factor  \\\n",
       "0     20         7.24    7     3           96          0.806452   \n",
       "1     22  1.13078e+06    3     3          104          0.880282   \n",
       "2   1308         9323  NaN     4          NaN          1.650165   \n",
       "3     75        296.3   10     4          104          0.580720   \n",
       "4   1670         6020  NaN     3          NaN          0.444565   \n",
       "\n",
       "  budget_adjusted box_office_adjusted  \n",
       "0          16.129             5.83871  \n",
       "1         19.3662              995409  \n",
       "2         2158.42             15384.5  \n",
       "3          43.554             172.067  \n",
       "4         742.424             2676.28  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DataFrame for 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'director': ['Josh Safdie Benny Safdie'],\n",
       " 'genre': ['cri', 'thr'],\n",
       " 'producer': ['Scott Rudin', 'Eli Bush', 'Sebastian Bear-McClard'],\n",
       " 'screenplay': ['Ronald Bronstein', 'Josh Safdie', 'Benny Safdie'],\n",
       " 'cast': ['Adam Sandler',\n",
       "  'Lakeith Stanfield',\n",
       "  'Julia Fox',\n",
       "  'Kevin Garnett',\n",
       "  'Idina Menzel',\n",
       "  'Eric Bogosian',\n",
       "  'Judd Hirsch',\n",
       "  'Keith Williams Richards',\n",
       "  'Mike Francesa',\n",
       "  'Jonathan Aranbayev',\n",
       "  'Noa Fisher',\n",
       "  'Abel Tesfaye'],\n",
       " 'music': ['Daniel Lopatin'],\n",
       " 'cinematography': ['Darius Khondji'],\n",
       " 'edit': ['Ronald Bronstein', 'Benny Safdie'],\n",
       " 'year': 2019,\n",
       " 'running_time': 135,\n",
       " 'language': ['English'],\n",
       " 'box_office': 2.2}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_dict_2019['uncut gems',2019]['imdbID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the courier 2019\n",
      "the courier 2019\n",
      "Broken!\n",
      "old possum's book of practical cats 2019\n",
      "\tCould not prepare DataFrame for old possum's book of practical cats. Movie info missing!\n",
      "henry iv, part 1 2019\n",
      "\tCould not prepare DataFrame for henry iv, part 1. Movie info missing!\n",
      "henry iv, part 2 2019\n",
      "\tCould not prepare DataFrame for henry iv, part 2. Movie info missing!\n",
      "henry v 2019\n",
      "henry v 2019\n",
      "Broken!\n",
      "the surgeon of crowthorne 2019\n",
      "\tCould not prepare DataFrame for the surgeon of crowthorne. Movie info missing!\n",
      "the queen's corgi 2019\n",
      "robert the bruce 2019\n",
      "pain and glory 2019\n",
      "\tCould not prepare DataFrame for pain and glory. Movie info missing!\n",
      "transit 2019\n",
      "\tCould not prepare DataFrame for transit. Movie info missing!\n",
      "(254, 10)\n",
      "after dropna() (254, 10)\n",
      "Done!\n",
      "(254, 13)\n",
      "CPU times: user 1.05 s, sys: 104 ms, total: 1.15 s\n",
      "Wall time: 1.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create DataFrame for year 2019 and SAVE as df_movies_2019\n",
    "movie_dict_2019 = pickle.load(open(\"my_data_4/movie_dict_2019\",\"rb\"))\n",
    "\n",
    "columns = ['imdbID','title','year','n_votes','imdb_rating','budget', 'box_office','cast', 'genre','running_time']\n",
    "df_movies_2019, rejected = create_dataframe_from_dict2(movie_dict_2019, columns,[2019])\n",
    "print(df_movies_2019.shape)\n",
    "df_movies_2019 = df_movies_2019[df_movies_2019.year==2019]\n",
    "# df_movies_2019 = df_movies_2019.dropna()\n",
    "print('after dropna()',df_movies_2019.shape)\n",
    "print('Done!')\n",
    "\n",
    "# Convert year column from integer to date_time and SAVE\n",
    "# yr_column = pd.to_datetime(df_movies.year.astype('int'), format='%Y')\n",
    "df_movies_2019.year = [y.year for y in pd.to_datetime(df_movies_2019.year.astype('int'), format='%Y')]\n",
    "df_movies_2019.reset_index(inplace=True, drop=True)\n",
    "df_movies_2019.head()\n",
    "\n",
    "#df_movies_2019.to_csv('my_data_4/df_movies_2019_2.csv')\n",
    "\n",
    "# Adjust for inflation\n",
    "cpi = pd.read_csv('my_data_4/CPI_index.csv')\n",
    "cpi.rename({'Year':'year'}, axis = 1,inplace=True)\n",
    "cpi.set_index('year', inplace=True)\n",
    "cpi.loc[2019,'Avg']=255.0 # 2019 information was missing and entered manually\n",
    "\n",
    "cpi = cpi[['Avg']]\n",
    "cpi['factor'] = 1/(cpi.Avg/100)\n",
    "cpi.tail()\n",
    "\n",
    "# Create new DataFrame adjusting for inflation\n",
    "df_budget = df_movies_2019[['year', 'budget']]                  \n",
    "df_movies_2019['inflation_factor'] = [cpi.loc[x,'factor'] for x in df_movies_2019.year]\n",
    "df_movies_2019['budget_adjusted'] = df_movies_2019['budget']*df_movies_2019['inflation_factor']\n",
    "df_movies_2019['box_office_adjusted'] = df_movies_2019['box_office']*df_movies_2019['inflation_factor']\n",
    "\n",
    "print(df_movies_2019.shape)\n",
    "df_movies_2019.to_csv('my_data_4/df_movies_2019.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Data Acquisition for Academy Awards with Webscraping and API\n",
    "<a id=\"acquisition\"></a>\n",
    "\n",
    "We will use BeautifulSoup for web-scraping together with the wikipedia API to obtain information about the most popular films released between 1960 and 2019 and the various Academy Awards nominations and wins during that period. Out goal is to look at hollywood films under three categories of performance: awards, critical review and revenue to identify what predicts the success of a movie. \n",
    "\n",
    "In other words, we see each film in terms of its measurable and identifiable features and see hwo they contributed to the success of a movie. Are big budget movies more likely to win awards? Is it the size or profile of the cast size that are likely to draw a more critically acclaim? Are longer movies more popular among the award committe and the fans alike?\n",
    "\n",
    "In order to obtain clean and reliable movie information and their awards and nomination in the different film categories, we use two APIs: the wikiedpa API and the omdb API. \n",
    "\n",
    "We also use the BeautifulSoup module aloing with regular expressions (re) to extract the various information from wikipedia and IMDB to obtain the most reliable information about films. \n",
    "\n",
    "## 2.2 Web scraping from Wikipedia\n",
    "\n",
    "The following function obtained information about a film, namely its director, cast, running time, budget and box office information as shown below for Lawrence of Arabia (1962), which was used for predicting the Oscars for 2020. \n",
    "The information is returned as a Python dictionary.\n",
    "<br>\n",
    "<img src=\"files/wiki4.png\" height=\"100\" width=\"100\" align=\"left\" style=\"width:40%\">\n",
    "<img src=\"files/wiki2.png\" height=\"100\" width=\"100\" align=\"center\" style=\"width:40%\">\n",
    "\n",
    "\n",
    "## 2.1 The Wikipedia API\n",
    "The following function accepts a title, year or category and obtains the HTML document for the relevant wikipedia page. \n",
    "\n",
    "The wikpedia pages for the Academy Awars expect get request not in the specification of year (eg. 1974 Academy Awards), but in the form of \"N<sup>th</sup> Academy Awards, such as <a href=\"https://en.wikipedia.org/wiki/34th_Academy_Awards\">\"34th Academy Awards\"</a>\". The same wikipedia API can can individual film information if movie and year are specified, and The Academy Awards information for a given year as shwon below.\n",
    "<br>\n",
    "\n",
    "#### Getting Oscar Editions\n",
    "The Wikipedia page for The Academy Awards is referenced **not** by the year (eg. 1962 Academy Awards) but by its edition (34th Academy Awards) as shown below. \n",
    "<br>\n",
    "<img src=\"files/wiki.jpeg\" height=\"800\" width=\"800\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Wikipedia pages for Academy Awards are listed in terms of their edition: 1st, 2nd, 3rd, etc.\n",
    "\n",
    "\n",
    "def wikiapi_nth(year, award = ' Academy Awards'):\n",
    "    year =get_edition(year)\n",
    "    year_award_wikiformat = year + award\n",
    "    try:\n",
    "        return wikipedia.page(year_award_wikiformat)\n",
    "    except wikipedia.exceptions.PageError:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        return wikipedia.page(year_award_wikiformat.replace(' ','_'))\n",
    "    except wikipedia.exceptions.PageError:\n",
    "        print(f\"The page for the year {year_award_wikiformat} could not be found \")\n",
    "        return\n",
    "\n",
    "########################################################\n",
    "def get_edition(year):\n",
    "    '''Takes in a year and returns the edition of the given year's oscars\n",
    "    eg: Academy Awards, 1930 and returns 2nd Academy Awards'''\n",
    "    \n",
    "    # Define editiona\n",
    "    editions = ['th','st', 'nd', 'rd','th', 'th', 'th', 'th', 'th', 'th', 'th']\n",
    "    # editions_dict = {}\n",
    "    nth = year - 1928\n",
    "    if nth>10 and nth<20:\n",
    "        year_th = str(nth)+'th'\n",
    "    else:\n",
    "        year_th = str(nth) + editions[nth%10]\n",
    "    return year_th\n",
    "\n",
    "\n",
    "#########################################################\n",
    "def get_genre(intro):\n",
    "    \"\"\"Takes in the intro paragraph from Wikipedia and scrapes out information about genre\n",
    "    \"\"\"\n",
    "    genre_dict = pickle.load(open(\"my_data_2/genre_dict\",\"rb\"))\n",
    "    this_movie_genres = []\n",
    "    for line in intro: # got through all the lines\n",
    "        line = line.text.split('.')\n",
    "        line = line[0]\n",
    "        line = line.lower()\n",
    "        for genre in genre_dict:\n",
    "            if line.find(genre) > 0:\n",
    "                this_movie_genres.append(genre_dict[genre])\n",
    "        \n",
    "        if len(this_movie_genres)>0:\n",
    "            return list(set(this_movie_genres))\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['picture', 'director', 's_actor', 's_actress', 'actor', 'actress', 'screenplay']\n",
      "['music', 'cinematography', 'editing', 'effects', 'sound', 'costume', 'song', 'art_direction']\n",
      "['picture', 'director', 's_actor', 's_actress', 'actor', 'actress', 'screenplay', 'music', 'cinematography', 'editing', 'effects', 'sound', 'costume', 'song', 'art_direction']\n"
     ]
    }
   ],
   "source": [
    "# Categories definition\n",
    "major_categories = ['picture','director','s_actor','s_actress','actor', \n",
    "                   'actress','screenplay']\n",
    "minor_categories = ['music','cinematography','editing','effects','sound',\n",
    "                    'costume','song', 'art_direction']\n",
    "all_categories = major_categories + minor_categories\n",
    "\n",
    "pickle.dump(major_categories,open( 'my_data_4/major_categories', \"wb\" ))\n",
    "pickle.dump(minor_categories,open( 'my_data_4/minor_categories', \"wb\" ))\n",
    "pickle.dump(all_categories,open( 'my_data_4/all_categories', \"wb\" ))\n",
    "\n",
    "print(major_categories)\n",
    "print(minor_categories)\n",
    "print(all_categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_main_category(category):\n",
    "    \"\"\"This function accepts variants of basic cateries such as \n",
    "    'Best Motion Picture' and 'Best Picture' and 'Outstanding Picture'\n",
    "    and returns \"picture\"\n",
    "    \"\"\"\n",
    "    category = category.lower()\n",
    "\n",
    "    if category.find('story')>=0:\n",
    "        return 'other'\n",
    "    if category.find('best picture')>=0 or category.find('best motion picture')>=0:\n",
    "        return 'picture'\n",
    "    if category.find('outstanding production')>=0 or category.find('outstanding picture')>=0:\n",
    "        return 'picture'\n",
    "    if category.find('actor')>=0:\n",
    "        if category.find('supporting')>=0:\n",
    "            return 's_actor'\n",
    "        else:\n",
    "            return 'actor'   \n",
    "    if category.find('actress')>=0:\n",
    "        if category.find('supporting')>=0:\n",
    "            return 's_actress'\n",
    "        else:\n",
    "            return 'actress'    \n",
    "    if category.find('best director')>=0:\n",
    "        return 'director'\n",
    "    if category.find('screenplay')>=0:\n",
    "        return 'screenplay'\n",
    "    if category.find('music')>=0 or (category.find('scor')>=0):\n",
    "        return 'music'\n",
    "    if category.find('costume')>=0:\n",
    "        return 'costume'\n",
    "    if category.find('editing')>=0:\n",
    "        return 'editing'\n",
    "    if category.find('effects')>=0:\n",
    "        return 'effects'\n",
    "    if category.find('cinematography')>=0:\n",
    "        return 'cinematography'\n",
    "    if category.find('sound')>=0:\n",
    "        return 'sound'\n",
    "    if category.find('song')>=0:\n",
    "        return 'song'\n",
    "    if category.find('art')>=0 and category.find('direct')>=0:\n",
    "        return 'art_direction'\n",
    "    # if category.find('art direction')>=0:\n",
    "        # return 'art direction'\n",
    "    else:\n",
    "        # print(f'Warning:{category} did not get matched!')\n",
    "        return 'other'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Film Awards and Nominations\n",
    "The following function obtains movie information at the level of the mlovie and NOT the individual winners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Awards and Nominations\n",
    "def awards_and_nominations(year, award = ' Academy Awards', all_categories = 'all'):\n",
    "    '''This function accepts year, title or award and goes into the wikipedia page of the Award \n",
    "    or the Movie and extrac t all the necessary information.\n",
    "    '''\n",
    "    \n",
    "    if all_categories=='all':\n",
    "        all_categories = pickle.load(open(\"my_data_4/all_categories\",\"rb\")) \n",
    "\n",
    "    \n",
    "    # initialize empty DataFrame and the corresponding Screening Number\n",
    "    oscars_wn = pd.DataFrame()\n",
    "    missing_categories = []\n",
    "    winner_list = dict()\n",
    "    nominee_list = dict()\n",
    "    \n",
    "    # Get the html file from the Wikipedia page using the wikipedia API.\n",
    "    # Parse it with BeautifulSoup\n",
    "    page = wikiapi_nth(year)\n",
    "    soup = BeautifulSoup(page.html(),'lxml')\n",
    "    print(get_edition(year))\n",
    "        \n",
    "    # Get the table-body (tbody) from the wikipedia page where Oscars information are stored\n",
    "    tbody = soup.body.find('table', class_=\"wikitable\").find('tbody')\n",
    "       \n",
    "    # Make sure number of cells and header match\n",
    "    if len(tbody.find_all('td')) !=len(tbody.find_all(['div', 'th'])):\n",
    "    \n",
    "        # The wikipedia tables needs to be fixed! Some category header may be missing.\n",
    "        print('Warning: Number of cell <td> element  and header <th> does not add up for year:', year)\n",
    "        print('Returned Empty dataFrame')\n",
    "        return oscars_wn, missing_categories\n",
    "        \n",
    "        \n",
    "    # Get winners and nominees\n",
    "    try:\n",
    "        for td,th in zip(tbody.find_all('td'),tbody.find_all(['div', 'th'])):\n",
    "            cat = th.text.strip()\n",
    "            # Get standardized categories\n",
    "            category = get_main_category(cat)\n",
    "            if category not in all_categories:\n",
    "                continue\n",
    "            winner_list[category] = [] # inditialize an empty dictionary\n",
    "            nominee_list[category] = []\n",
    "\n",
    "            if category=='other':\n",
    "                missing_categories.append(cat)\n",
    "                # print(f'Warning in {category} in {year}')\n",
    "\n",
    "            # Go into the list and look at every line\n",
    "            for tli in td.find_all('li'):\n",
    "                # go down each line (li) and check if it is bolded\n",
    "                if tli.find('b')!= None: # winner\n",
    "                    winner = tli.find('i').text.strip()       # get italicized movie\n",
    "                    winner = re.sub(r'–',\"\", winner).strip()\n",
    "                    winner = winner.lower()\n",
    "                    winner_list[category].append(winner) # add movie to winner list\n",
    "                    oscars_wn.loc[winner,'year']= int(year)-1\n",
    "                    oscars_wn.loc[winner,category]='W'\n",
    "                    \n",
    "                elif tli.find('b')== None: #nominee\n",
    "                    nominee = tli.find('i').text.strip()      # get italicized movie\n",
    "                    nominee = re.sub(r'–',\"\", nominee).strip()\n",
    "                    nominee = nominee.lower()\n",
    "                    nominee_list[category].append(nominee)\n",
    "                    oscars_wn.loc[nominee,'year']= int(year)-1\n",
    "                    if nominee in winner_list[category]: # if same movie has already won, leave it unchanged as 'W'\n",
    "                        oscars_wn.loc[nominee,category]='WN'\n",
    "                    else:\n",
    "                        oscars_wn.loc[nominee,category]='N'\n",
    "\n",
    "        \n",
    "    except AttributeError:\n",
    "        print(f'Warning: in Category {category} for Year: {year}')\n",
    "            \n",
    "\n",
    "    # oscars_wn['film'] = oscars_wn.index\n",
    "    return oscars_wn.fillna('O'), missing_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In year 2010\n",
      "82nd\n",
      "83rd\n",
      "84th\n",
      "85th\n",
      "86th\n",
      "87th\n",
      "88th\n",
      "89th\n",
      "90th\n",
      "91st\n",
      "                           film actor actress art_direction cinematography  \\\n",
      "0            gone with the wind     N       W             W              W   \n",
      "1                  dark victory     O       N             O              O   \n",
      "2            goodbye, mr. chips     W       N             O              O   \n",
      "3                   love affair     O       N             N              O   \n",
      "4  mr. smith goes to washington     N       O             N              O   \n",
      "\n",
      "  costume director editing effects music picture s_actor s_actress screenplay  \\\n",
      "0     NaN        W       W       N     N       W       O        WN          W   \n",
      "1     NaN        O       O       O     N       N       O         O          O   \n",
      "2     NaN        N       N       O     O       N       O         O          N   \n",
      "3     NaN        O       O       O     O       N       O         N          O   \n",
      "4     NaN        N       N       O     N       N       N         O          N   \n",
      "\n",
      "  song sound  year  \n",
      "0    O     N  1939  \n",
      "1    O     O  1939  \n",
      "2    O     N  1939  \n",
      "3    N     O  1939  \n",
      "4    O     N  1939  \n",
      "                           film  year category result\n",
      "0            gone with the wind  1939    actor      N\n",
      "1                  dark victory  1939    actor      O\n",
      "2            goodbye, mr. chips  1939    actor      W\n",
      "3                   love affair  1939    actor      O\n",
      "4  mr. smith goes to washington  1939    actor      N\n",
      "CPU times: user 21.2 s, sys: 608 ms, total: 21.8 s\n",
      "Wall time: 2min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# GET MOVIE AWARDS FROM ALL CATEGORIES\n",
    "\n",
    "df_oscars_wide = pd.DataFrame()\n",
    "for year in range(1940,2020):\n",
    "    if year%10==0:\n",
    "        clear_output()\n",
    "        print(f'In year {year}')\n",
    "    df, missing = awards_and_nominations(year)\n",
    "    df_oscars_wide = df_oscars_wide.append(df)\n",
    "\n",
    "# Convert year to datwetime, removes Nans and SAVE\n",
    "df_oscars_wide.year = df_oscars_wide.year.astype('int').astype('str')\n",
    "x = pd.to_datetime(df_oscars_wide.year, format='%Y', exact=True)\n",
    "df_oscars_wide.year = [x.year for x in pd.to_datetime(df_oscars_wide.year, format='%Y', exact=True)]\n",
    "df_oscars_wide.reset_index(inplace=True)\n",
    "df_oscars_wide.rename(columns = {'index':'film'},inplace=True)\n",
    "print(df_oscars_wide.head())\n",
    "\n",
    "#Perpare and save long version and SAVE\n",
    "df_oscars_long = pd.melt(df_oscars_wide, id_vars = ['film', 'year'], var_name='category', value_name = 'result')\n",
    "print(df_oscars_long.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2547, 17)\n",
      "(38205, 4)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2547 entries, 0 to 2546\n",
      "Data columns (total 17 columns):\n",
      "title             2547 non-null object\n",
      "actor             2547 non-null object\n",
      "actress           2547 non-null object\n",
      "art_direction     2547 non-null object\n",
      "cinematography    2547 non-null object\n",
      "costume           2547 non-null object\n",
      "director          2547 non-null object\n",
      "editing           2547 non-null object\n",
      "effects           2547 non-null object\n",
      "music             2547 non-null object\n",
      "picture           2547 non-null object\n",
      "s_actor           2547 non-null object\n",
      "s_actress         2547 non-null object\n",
      "screenplay        2547 non-null object\n",
      "song              2547 non-null object\n",
      "sound             2547 non-null object\n",
      "year              2547 non-null int64\n",
      "dtypes: int64(1), object(16)\n",
      "memory usage: 338.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_oscars_wide.fillna('O',inplace=True)\n",
    "print(df_oscars_wide.shape)\n",
    "print(df_oscars_long.shape)\n",
    "df_oscars_wide.rename(columns = {'film':'title'},inplace=True)\n",
    "df_oscars_wide.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oscars_wide.to_csv('my_data_4/df_oscars_wide.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          title  year category result\n",
      "0            gone with the wind  1939    actor      N\n",
      "1                  dark victory  1939    actor      O\n",
      "2            goodbye, mr. chips  1939    actor      W\n",
      "3                   love affair  1939    actor      O\n",
      "4  mr. smith goes to washington  1939    actor      N\n"
     ]
    }
   ],
   "source": [
    "df_oscars_long = pd.melt(df_oscars_wide, id_vars = ['title', 'year'], var_name='category', value_name = 'result')\n",
    "print(df_oscars_long.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oscars_long.to_csv('my_data_4/df_oscars_long.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Awards and Nomination\n",
    "The previous function obtained information about the varioiius winners and nominees at the movie level. The next function obtains information in the individual categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Awards and Nominations for individuals: actor, actress, director\n",
    "def individual_awards_and_nominations(year, get_categories ='all', award =' Academy Awards'):\n",
    "    '''This function accepts year, title or award and goes into the wikipedia page of the Award \n",
    "    or the Movie and extracts all the necessary information for INDIVIDUAL winners, example \n",
    "    Steven Spielberg in directing and Tom Hanks in Actor category etc. \n",
    "    '''\n",
    "    \n",
    "    if get_categories == 'all':\n",
    "        get_categories = pickle.load(open(\"my_data_3/main_categories\",\"rb\"))\n",
    "\n",
    "    \n",
    "    # initialize empty DataFrame and the corresponding Screening Number\n",
    "    individual_wn = pd.DataFrame()\n",
    "    missing_categories = []\n",
    "    idx = 0\n",
    "    \n",
    "    # Get the html file from the Wikipedia page using the wikipedia API.\n",
    "    # Parse it with BeautifulSoup\n",
    "    page = wikiapi_nth(year)\n",
    "    soup = BeautifulSoup(page.html(),'lxml')\n",
    "        \n",
    "    # Get the table-body (tbody) from the wikipedia page where Oscars information are stored\n",
    "    tbody = soup.body.find('table', class_=\"wikitable\").find('tbody')\n",
    "       \n",
    "    # Make sure number of cells and header match\n",
    "    if len(tbody.find_all('td')) !=len(tbody.find_all(['div', 'th'])):\n",
    "    \n",
    "        # The wikipedia tables needs to be fixed! Some category header may be missing.\n",
    "        print('Warning: Number of cell <td> element  and header <th> does not add up for year:', year)\n",
    "        print('Returned Empty dataFrame')\n",
    "        return individual_wn, missing_categories\n",
    "        \n",
    "        \n",
    "    # Get winners and nominees\n",
    "    try:\n",
    "        for td,th in zip(tbody.find_all('td'),tbody.find_all(['div', 'th'])):\n",
    "            cat = th.text.strip()\n",
    "            category = get_main_category(cat)\n",
    "            # print('\\nCategory:', category)\n",
    "            if category not in get_categories:\n",
    "                # print(year, category)\n",
    "                continue\n",
    "\n",
    "            # Go into the list and remove the film names in <i> italic tags\n",
    "            for line in td.find_all('li'):\n",
    "                if line.find('i') != None:\n",
    "                    line.i.decompose() # remove film\n",
    "                    \n",
    "                if line.find('b')!= None: # if in bold then winner\n",
    "                    for wins in line.find_all('b'):\n",
    "                        if wins.find('i') != None: # remove film\n",
    "                            wins.i.decompose()\n",
    "                            \n",
    "                        if wins.find('a')!=None: # winner will be the first hyperlink\n",
    "                            winner = wins.find_all('a')[0].text.strip()\n",
    "                        else:\n",
    "                            winner = wins.text.strip() #if no hyperlink, winner is first text\n",
    "                        winner = re.sub(r'–',\"\", winner).strip()\n",
    "                        if winner != None:\n",
    "                            individual_wn.loc[idx,'year']= int(year)\n",
    "                            individual_wn.loc[idx, 'name']= winner\n",
    "                            individual_wn.loc[idx, 'category']= category\n",
    "                            individual_wn.loc[idx, 'result']= 'W'\n",
    "                            idx = idx + 1\n",
    "                \n",
    "                elif line.find('b') == None: # if no bold then not a winner\n",
    "                    if line.find('a') != None:\n",
    "                        nominee = line.find_all('a')[0].text.strip()\n",
    "                    else:\n",
    "                        nominee = line.text.strip()\n",
    "                    nominee = re.sub(r'–',\"\", nominee).strip()\n",
    "                    if nominee != None:\n",
    "                        individual_wn.loc[idx,'year']= int(year)\n",
    "                        individual_wn.loc[idx, 'name']= nominee\n",
    "                        individual_wn.loc[idx, 'category']= category\n",
    "                        individual_wn.loc[idx, 'result']= 'N'\n",
    "                        idx = idx + 1\n",
    "\n",
    "        \n",
    "    except AttributeError:\n",
    "        print(f'Warning: in Category {category} for Year: {year}')\n",
    "\n",
    "    return individual_wn, missing_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# GET INDIVIDUAL AWARDS FROM ALL CATEGORIES\n",
    "get_categories = 'all'\n",
    "df_individual_long = pd.DataFrame()\n",
    "for year in range(1940,2020):\n",
    "    if year%10==0:\n",
    "        print(f'In year {year}')\n",
    "    df, missing = individual_awards_and_nominations(year)\n",
    "    df_individual_long = df_individual_long.append(df)\n",
    "\n",
    "\n",
    "# Convert year to datetime, and SAVE\n",
    "df_individual_long.year = df_individual_long.year.astype('int').astype('str')\n",
    "x = pd.to_datetime(df_individual_long.year, format='%Y', exact=True)\n",
    "df_individual_long.year = [x.year for x in pd.to_datetime(df_individual_long.year, format='%Y', exact=True)]\n",
    "df_individual_long.reset_index(inplace=True)\n",
    "df_individual_long.to_csv('my_data_3/df_individual_long.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Missing Movies\n",
    "\n",
    "Some movies that have won Academy Award nominations are missing from the movie_dictionary and data frame because they were npot listed in the original IMDB dataset. Thes emovies will now be included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oscars_wide = pd.read_csv('my_data_4/df_oscars_wide.csv', index_col=[0])\n",
    "movie_dict = pickle.load(open(\"my_data_4/movie_dict\",\"rb\"))\n",
    "df_movies = pd.read_csv('my_data_4/df_movies.csv', index_col=[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching information for the pleasure seekers,1965\n",
      "the pleasure seekers\n",
      "Could not find infobox for the pleasure seekers\n",
      "Fetching information for blowup,1966\n",
      "blowup\n",
      "Unknown error in blowup: could not fetch info\n",
      "Fetching information for return of the seven,1966\n",
      "return of the seven\n",
      "\treturn of the seven not found in OMDB API\n",
      "Fetching information for gambit,1966\n",
      "gambit\n",
      "Could not find infobox for gambit\n",
      "Fetching information for mandragola,1966\n",
      "mandragola\n",
      "Warning: The Wikipedia page for the title mandragola could not be found without date \n",
      "mandragola (film)\n",
      "Wikipedia could not get mandragola in 1966\n",
      "Fetching information for rachel, rachel,1968\n",
      "rachel, rachel\n",
      "Fetching information for the fox,1968\n",
      "the fox\n",
      "Could not find infobox for the fox\n",
      "Fetching information for chitty chitty bang bang,1968\n",
      "chitty chitty bang bang\n",
      "Fetching information for goodbye, mr. chips,1969\n",
      "goodbye, mr. chips\n",
      "Could not find infobox for goodbye, mr. chips\n",
      "Fetching information for m*a*s*h,1970\n",
      "m*a*s*h\n",
      "Could not find infobox for m*a*s*h\n",
      "Fetching information for i girasoli,1970\n",
      "i girasoli\n",
      "Wikipedia could not get i girasoli in 1970\n",
      "Fetching information for madron,1970\n",
      "madron\n",
      "Could not find infobox for madron\n",
      "Fetching information for mccabe & mrs. miller,1971\n",
      "mccabe & mrs. miller\n",
      "Unknown error in mccabe & mrs. miller: could not fetch info\n",
      "Fetching information for bless the beasts and children,1971\n",
      "bless the beasts and children\n",
      "\tbless the beasts and children not found in OMDB API\n",
      "Fetching information for cries and whispers,1973\n",
      "cries and whispers\n",
      "Wikipedia could not get cries and whispers in 1973\n",
      "Fetching information for jacqueline susann's once is not enough,1975\n",
      "jacqueline susann's once is not enough\n",
      "\tjacqueline susann's once is not enough not found in OMDB API\n",
      "Fetching information for profumo di donna,1975\n",
      "profumo di donna\n",
      "Wikipedia could not get profumo di donna in 1975\n",
      "Fetching information for looking for mr. goodbar,1977\n",
      "looking for mr. goodbar\n",
      "\tlooking for mr. goodbar not found in OMDB API\n",
      "Fetching information for superman,1978\n",
      "superman\n",
      "Could not find infobox for superman\n",
      "Fetching information for mon oncle d'amerique,1980\n",
      "mon oncle d'amerique\n",
      "Wikipedia could not get mon oncle d'amerique in 1980\n",
      "Fetching information for a soldier's story as,1984\n",
      "a soldier's story as\n",
      "\ta soldier's story as not found in OMDB API\n",
      "Fetching information for the karate kid as,1984\n",
      "the karate kid as\n",
      "\tthe karate kid as not found in OMDB API\n",
      "Fetching information for greystoke: the legend of tarzan, lord of the apes as,1984\n",
      "greystoke: the legend of tarzan, lord of the apes as\n",
      "\tgreystoke: the legend of tarzan, lord of the apes as not found in OMDB API\n",
      "Fetching information for the natural as,1984\n",
      "the natural as\n",
      "Could not find infobox for the natural as\n",
      "Fetching information for swing shift as,1984\n",
      "swing shift as\n",
      "\tswing shift as not found in OMDB API\n",
      "Fetching information for the pope of greenwich village as,1984\n",
      "the pope of greenwich village as\n",
      "\tthe pope of greenwich village as not found in OMDB API\n",
      "Fetching information for the north,1984\n",
      "the north\n",
      "Warning: The Wikipedia page for the title the north could not be found without date \n",
      "the north (1984_film)\n",
      "Could not find infobox for the north\n",
      "Fetching information for kiss of the spider woman,1985\n",
      "kiss of the spider woman\n",
      "Warning: The Wikipedia page for the title kiss of the spider woman could not be found without date \n",
      "\tThe Wikipedia page for the title kiss of the spider woman could not be found \n",
      "Fetching information for camille claudel,1989\n",
      "camille claudel\n",
      "Could not find infobox for camille claudel\n",
      "Fetching information for batman,1989\n",
      "batman\n",
      "Could not find infobox for batman\n",
      "Fetching information for mr. and mrs. bridge,1990\n",
      "mr. and mrs. bridge\n",
      "\tmr. and mrs. bridge not found in OMDB API\n",
      "Fetching information for madame bovary,1991\n",
      "madame bovary\n",
      "Could not find infobox for madame bovary\n",
      "Fetching information for mr. saturday night,1992\n",
      "mr. saturday night\n",
      "\tmr. saturday night not found in OMDB API\n",
      "Fetching information for babe,1995\n",
      "babe\n",
      "Warning: The Wikipedia page for the title babe could not be found without date \n",
      "babe (film)\n",
      "Fetching information for il postino: the postman,1995\n",
      "il postino: the postman\n",
      "Wikipedia could not get il postino: the postman in 1995\n",
      "Fetching information for mr. holland's opus,1995\n",
      "mr. holland's opus\n",
      "\tmr. holland's opus not found in OMDB API\n",
      "Fetching information for the preacher's wife,1996\n",
      "the preacher's wife\n",
      "Fetching information for the talented mr. ripley,1999\n",
      "the talented mr. ripley\n",
      "\tthe talented mr. ripley not found in OMDB API\n",
      "Fetching information for the emperor's new groove,2000\n",
      "the emperor's new groove\n",
      "Fetching information for adaptation,2002\n",
      "adaptation\n",
      "Could not find infobox for adaptation\n",
      "Fetching information for spider-man,2002\n",
      "spider-man\n",
      "Could not find infobox for spider-man\n",
      "Fetching information for precious: based on the novel 'push' by sapphire,2009\n",
      "precious: based on the novel 'push' by sapphire\n",
      "\tprecious: based on the novel 'push' by sapphire not found in OMDB API\n",
      "Fetching information for fantastic mr. fox,2009\n",
      "fantastic mr. fox\n",
      "\tfantastic mr. fox not found in OMDB API\n",
      "Fetching information for paris 36,2009\n",
      "paris 36\n",
      "Wikipedia could not get paris 36 in 2009\n",
      "Fetching information for marvel's the avengers,2012\n",
      "marvel's the avengers\n",
      "\tmarvel's the avengers not found in OMDB API\n",
      "Fetching information for saving mr. banks,2013\n",
      "saving mr. banks\n",
      "\tsaving mr. banks not found in OMDB API\n",
      "Fetching information for the invisible woman,2013\n",
      "the invisible woman\n",
      "Could not find infobox for the invisible woman\n",
      "Fetching information for mr. turner,2014\n",
      "mr. turner\n",
      "\tmr. turner not found in OMDB API\n",
      "Fetching information for 13 hours: the secret soldiers of benghazi,2016\n",
      "13 hours: the secret soldiers of benghazi\n",
      "\t13 hours: the secret soldiers of benghazi not found in OMDB API\n",
      "Fetching information for roman j. israel, esq.,2017\n",
      "roman j. israel, esq.\n",
      "\troman j. israel, esq. not found in OMDB API\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    for row in df_oscars_wide.iterrows():\n",
    "        idx = row[0]\n",
    "        title = row[1].film\n",
    "        year = row[1].year\n",
    "        if year < 1965:\n",
    "            continue\n",
    "        if (title, year) not in movie_dict or len(movie_dict[title,year])==0:\n",
    "            print(f'Fetching information for {title},{year}')\n",
    "            movie_dict[(title,year)] = get_all_movie_info(title, year)\n",
    "except WikipediaException:\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 30s, sys: 4.16 s, total: 1min 34s\n",
      "Wall time: 1min 35s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>imdbID</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>n_votes</th>\n",
       "      <th>imdb_rating</th>\n",
       "      <th>budget</th>\n",
       "      <th>box_office</th>\n",
       "      <th>cast</th>\n",
       "      <th>genre</th>\n",
       "      <th>running_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>tt0097626</td>\n",
       "      <td>johnny handsome</td>\n",
       "      <td>1989</td>\n",
       "      <td>8324</td>\n",
       "      <td>6.2</td>\n",
       "      <td>20</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>tt0092997</td>\n",
       "      <td>extreme prejudice</td>\n",
       "      <td>1987</td>\n",
       "      <td>5649</td>\n",
       "      <td>6.7</td>\n",
       "      <td>22</td>\n",
       "      <td>1.13078e+06</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>tt0120903</td>\n",
       "      <td>x-men</td>\n",
       "      <td>2000</td>\n",
       "      <td>545484</td>\n",
       "      <td>7.4</td>\n",
       "      <td>75</td>\n",
       "      <td>296.3</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>tt0077975</td>\n",
       "      <td>national lampoon's animal house</td>\n",
       "      <td>1978</td>\n",
       "      <td>106817</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3</td>\n",
       "      <td>141.6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>tt0091757</td>\n",
       "      <td>pirates</td>\n",
       "      <td>1986</td>\n",
       "      <td>7361</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1274</td>\n",
       "      <td>4560</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4891</td>\n",
       "      <td>6506</td>\n",
       "      <td>tt0452624</td>\n",
       "      <td>the good german</td>\n",
       "      <td>2006</td>\n",
       "      <td>23319</td>\n",
       "      <td>6</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4892</td>\n",
       "      <td>6507</td>\n",
       "      <td>tt0497116</td>\n",
       "      <td>an inconvenient truth</td>\n",
       "      <td>2006</td>\n",
       "      <td>78298</td>\n",
       "      <td>7.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>49.8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4893</td>\n",
       "      <td>6511</td>\n",
       "      <td>tt0857191</td>\n",
       "      <td>the visitor</td>\n",
       "      <td>2008</td>\n",
       "      <td>40468</td>\n",
       "      <td>7.6</td>\n",
       "      <td>4</td>\n",
       "      <td>18.1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4894</td>\n",
       "      <td>6518</td>\n",
       "      <td>tt1667353</td>\n",
       "      <td>mirror mirror</td>\n",
       "      <td>2012</td>\n",
       "      <td>80479</td>\n",
       "      <td>5.6</td>\n",
       "      <td>85</td>\n",
       "      <td>183</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4895</td>\n",
       "      <td>6529</td>\n",
       "      <td>tt4226388</td>\n",
       "      <td>victoria &amp; abdul</td>\n",
       "      <td>2017</td>\n",
       "      <td>46625</td>\n",
       "      <td>7.7</td>\n",
       "      <td>21</td>\n",
       "      <td>65.4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4896 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index     imdbID                            title  year n_votes  \\\n",
       "0         0  tt0097626                  johnny handsome  1989    8324   \n",
       "1         1  tt0092997                extreme prejudice  1987    5649   \n",
       "2         3  tt0120903                            x-men  2000  545484   \n",
       "3         5  tt0077975  national lampoon's animal house  1978  106817   \n",
       "4         6  tt0091757                          pirates  1986    7361   \n",
       "...     ...        ...                              ...   ...     ...   \n",
       "4891   6506  tt0452624                  the good german  2006   23319   \n",
       "4892   6507  tt0497116            an inconvenient truth  2006   78298   \n",
       "4893   6511  tt0857191                      the visitor  2008   40468   \n",
       "4894   6518  tt1667353                    mirror mirror  2012   80479   \n",
       "4895   6529  tt4226388                 victoria & abdul  2017   46625   \n",
       "\n",
       "     imdb_rating budget   box_office cast genre running_time  \n",
       "0            6.2     20         7.24    7     3           96  \n",
       "1            6.7     22  1.13078e+06    3     3          104  \n",
       "2            7.4     75        296.3   10     4          104  \n",
       "3            7.5      3        141.6    6     1          109  \n",
       "4            6.1   1274         4560    6     3          726  \n",
       "...          ...    ...          ...  ...   ...          ...  \n",
       "4891           6     32            6    3     4          105  \n",
       "4892         7.4    1.5         49.8    1     2           97  \n",
       "4893         7.6      4         18.1    4     1          103  \n",
       "4894         5.6     85          183    7     5          106  \n",
       "4895         7.7     21         65.4    6     5          111  \n",
       "\n",
       "[4896 rows x 11 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Create DataFrame up to year 2018 and SAVE as df_movies\n",
    "# movie_dict = pickle.load(open(\"my_data_4/movie_dict\",\"rb\"))\n",
    "columns = ['imdbID','title','year','n_votes','imdb_rating','budget', 'box_office','cast', 'genre','running_time']\n",
    "df_movies, rejected = create_dataframe_from_dict2(movie_dict, columns, range(1950,2019))\n",
    "print(df_movies.shape)\n",
    "df_movies = df_movies.dropna()\n",
    "df_movies = df_movies[df_movies.imdbID.duplicated() == False]\n",
    "print('after dropna()',df_movies.shape)\n",
    "print('Done!')\n",
    "\n",
    "# Convert year column from integer to date_time and SAVE\n",
    "# yr_column = pd.to_datetime(df_movies.year.astype('int'), format='%Y')\n",
    "df_movies.year = [y.year for y in pd.to_datetime(df_movies.year.astype('int'), format='%Y')]\n",
    "clear_output()\n",
    "df_movies.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
