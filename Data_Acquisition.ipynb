{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import wikipedia\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Data Acquisition\n",
    "\n",
    "Data will be acquired using two different approaches. First, movie datasets will be harvested from websites like Kaggle, Dataworld and statscrunch. Second, we will use the wikipedia API to extract basic movie information from the wikipedia page to fill in missing information about budget, running time and box office revenues. \n",
    "\n",
    "## 1.1. Reading directly from files\n",
    "We will create pandas tables from structured datasets containing information about Academy Award nominations and wins, IMDB ratings and budget/box office "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reading from cvs and excel files\n",
    "df_actor = pd.read_csv('Movies/Oscar_data/actors.csv')\n",
    "df_actress = pd.read_csv('Movies/Oscar_data/actresses.csv')\n",
    "df_oscar = pd.read_csv('Movies/oscar_database.csv')\n",
    "df_budget = pd.read_excel('Movies/statcrunch_budgetboxoffice.xlsx')\n",
    "df_imdb = pd.read_excel('Movies/statcrunch_IMDB.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Webscraping using wikipedia API\n",
    "\n",
    "We will use the wikipedia API to obtain information about the cast running time, budget and box office revenues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function fr obtaining movie data using omdb API\n",
    "def omdbapi(title):\n",
    "    if not isinstance(title, str):\n",
    "        return {}\n",
    "    \n",
    "    url_base = 'http://www.omdbapi.com/?i=tt3896198&apikey=5db77b44&'\n",
    "    url = url_base + 't=' + str(title)\n",
    "    r = requests.get(url)\n",
    "    json_data = r.json()\n",
    "    return json_data\n",
    "\n",
    "# Define function fr obtaining movie data using Wikipedia API\n",
    "def wikiapi(title):\n",
    "    title = title + '(film)'\n",
    "    return wikipedia.page(title)\n",
    "\n",
    "def wikiscrape(title):\n",
    "    url = 'https://en.wikipedia.org/wiki/' + title\n",
    "    my_client = urlopen(url)\n",
    "    page_html = my_client.read()\n",
    "    my_client.close()\n",
    "    return page_html\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie = 'stardust_memories'\n",
    "# x = omdbapi(movie)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "[<tr><th class=\"summary\" colspan=\"2\" style=\"text-align:center;font-size:125%;font-weight:bold;font-size:110%;font-style:italic;\">stardust memories</th></tr>, <tr><td colspan=\"2\" style=\"text-align:center\"><a class=\"image\" href=\"/wiki/file:stardust_memories_moviep.jpg\"><img alt=\"stardust memories moviep.jpg\" class=\"thumbborder\" data-file-height=\"394\" data-file-width=\"253\" decoding=\"async\" height=\"343\" src=\"//upload.wikimedia.org/wikipedia/en/thumb/3/37/stardust_memories_moviep.jpg/220px-stardust_memories_moviep.jpg\" srcset=\"//upload.wikimedia.org/wikipedia/en/3/37/stardust_memories_moviep.jpg 1.5x\" width=\"220\"/></a><div style=\"font-size:95%;padding:0.35em 0.35em 0.25em;line-height:1.25em;\">theatrical release poster</div></td></tr>, <tr><th scope=\"row\" style=\"white-space:nowrap;padding-right:0.65em;\">directed by</th><td><a href=\"/wiki/woody_allen\" title=\"woody allen\">woody allen</a></td></tr>, <tr><th scope=\"row\" style=\"white-space:nowrap;padding-right:0.65em;\">produced by</th><td><a href=\"/wiki/robert_greenhut\" title=\"robert greenhut\">robert greenhut</a><br/><a href=\"/wiki/charles_h._joffe\" title=\"charles h. joffe\">charles h. joffe</a><br/><a href=\"/wiki/jack_rollins_(producer)\" title=\"jack rollins (producer)\">jack rollins</a></td></tr>, <tr><th scope=\"row\" style=\"white-space:nowrap;padding-right:0.65em;\">written by</th><td>woody allen</td></tr>, <tr><th scope=\"row\" style=\"white-space:nowrap;padding-right:0.65em;\">starring</th><td>woody allen<br/><a href=\"/wiki/charlotte_rampling\" title=\"charlotte rampling\">charlotte rampling</a><br/><a href=\"/wiki/jessica_harper\" title=\"jessica harper\">jessica harper</a><br/><a href=\"/wiki/marie-christine_barrault\" title=\"marie-christine barrault\">marie-christine barrault</a><br/><a href=\"/wiki/tony_roberts_(actor)\" title=\"tony roberts (actor)\">tony roberts</a></td></tr>, <tr><th scope=\"row\" style=\"white-space:nowrap;padding-right:0.65em;\">cinematography</th><td><a href=\"/wiki/gordon_willis\" title=\"gordon willis\">gordon willis</a></td></tr>, <tr><th scope=\"row\" style=\"white-space:nowrap;padding-right:0.65em;\">edited by</th><td><a href=\"/wiki/susan_e._morse\" title=\"susan e. morse\">susan e. morse</a></td></tr>, <tr><th scope=\"row\" style=\"white-space:nowrap;padding-right:0.65em;\">distributed by</th><td><a href=\"/wiki/united_artists\" title=\"united artists\">united artists</a></td></tr>, <tr><th scope=\"row\" style=\"white-space:nowrap;padding-right:0.65em;\"><div style=\"padding:0.1em 0;line-height:1.2em;white-space:normal;\">release date</div></th><td><div class=\"plainlist\">\n",
      "<ul><li>september 26, 1980<span style=\"display:none\"> (<span class=\"bday dtstart published updated\">1980-09-26</span>)</span></li></ul>\n",
      "</div></td></tr>, <tr><th scope=\"row\" style=\"white-space:nowrap;padding-right:0.65em;\"><div style=\"padding:0.1em 0;line-height:1.2em;white-space:normal;\">running time</div></th><td>88 minutes<sup class=\"reference\" id=\"cite_ref-1\"><a href=\"#cite_note-1\">[1]</a></sup></td></tr>, <tr><th scope=\"row\" style=\"white-space:nowrap;padding-right:0.65em;\">country</th><td>united states</td></tr>, <tr><th scope=\"row\" style=\"white-space:nowrap;padding-right:0.65em;\">language</th><td>english<br/>french<br/>persian</td></tr>, <tr><th scope=\"row\" style=\"white-space:nowrap;padding-right:0.65em;\">budget</th><td>$10 million</td></tr>, <tr><th scope=\"row\" style=\"white-space:nowrap;padding-right:0.65em;\">box office</th><td>$10.4 million</td></tr>]\n",
      "3414\n"
     ]
    }
   ],
   "source": [
    "# Using the wikipedia API to get the movie\n",
    "# Just like the search field, we do not have to provide exact name\n",
    "# We then parse the page using BeautifulSoup \n",
    "page = wikiapi(movie)\n",
    "soup = BeautifulSoup(page.html(),'html.parser')\n",
    "\n",
    "\n",
    "# Now find the infobox table within the page and extrcat it. \n",
    "# Ref: https://stackoverflow.com/questions/52913838/how-to-automate-scraping-wikipedia-info-box-specifically-and-print-the-data-usin?noredirect=1&lq=1\n",
    "table = soup.find('table', attrs={'class': 'infobox vevent'})\n",
    "infobox = table.find_all('tr')\n",
    "infobox = str(infobox).lower()\n",
    "print(type(infobox))\n",
    "print(infobox)\n",
    "print(len(infobox))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 million</td></tr>]\n"
     ]
    }
   ],
   "source": [
    "print(infobox[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(3283, 3290), match='million'>\n",
      "<re.Match object; span=(3396, 3403), match='million'>\n"
     ]
    }
   ],
   "source": [
    "## Extracting box office revenues using regular expressions\n",
    "pattern = re.compile(r'million')\n",
    "matches = pattern.finditer(infobox)\n",
    "for match in matches:\n",
    "    print(match)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
