{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>DATA ACQUISITION</center></h1>\n",
    "\n",
    "This project aims to analyze movie data from IMDB database based on 3 categories (commercial, critical and financial) and predict the nominees and winners for the The 92<sup>nd</sup> Academy Awards due to be held in 2020. \n",
    "\n",
    "The Data Acquisition phase will comprise of 3 steps:\n",
    "1. To obtain a list of English language films betwen the year 1955 to 2019\n",
    "2. To obtain the complete list of Academy Award winners and nominees, both in the film and individual categories\n",
    "\n",
    "By acquiring the latest and most updated data about films from **Wikipedia** and **IMDB** website of Hollywood films from 1940 to 2019, we will attempt to identify the key features that make films successful, popular and enduring. \n",
    "\n",
    "We will look at three key parameters:\n",
    "1. Accolades given by The Academy of Motion Pictures\n",
    "2. Box office revenues\n",
    "3. IMDB ratings based on fan reviews\n",
    "\n",
    "Based on these outcomes, we will explore the history of hollywood films and The Academy Awards to see what makes movies resonate with fans and endure over time. Why do some films become commercially successful but fail to win critical acclaim? Is there a correlation between budget and box-office revenues - do big budget moviesd make more money? Is there any significant correlation between how fans and the Academy view a film's success? \n",
    "\n",
    "By pooling data from various sources, defining metrics and measures that are simple and intuitive, we will try to uncover the secrets of great films. Using this knoweldge and information, we will try to predict the nominees and winners for the upcoming Oscars due to be held in 2020. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import wikipedia\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "from scrapy import selector\n",
    "import datetime as dt\n",
    "import pickle\n",
    "from skimage import io\n",
    "from IPython.display import clear_output\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Obtaining Movie List and Creating Initial Database\n",
    "\n",
    "For the project of analyzing movie success and predicting the Academy Award winner for the year 2020, our first step was to obtain a list of all major English films made between the years 1950 to 2019. In order to do that, we looked at the List of American abd British films made in each year in that period. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the 1950's\n",
      "In the 1960's\n",
      "In the 1970's\n",
      "In the 1980's\n",
      "In the 1990's\n",
      "In the 2000's\n",
      "In the 2010's\n",
      "CPU times: user 26.1 s, sys: 744 ms, total: 26.8 s\n",
      "Wall time: 6min 1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21995"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "primary_list = []\n",
    "for year in range(1950,2020):\n",
    "    if year%10==0:\n",
    "        print(f\"In the {year}'s\")\n",
    "    # Set URL\n",
    "    my_url = ['List_of_American_films_of_'+ str(year), 'List_of_British_films_of_'+ str(year)]\n",
    "    \n",
    "    #Define empty list for the year\n",
    "    \n",
    "    for url in my_url:\n",
    "        page = wikipedia.page(url)\n",
    "        soup = BeautifulSoup(page.html(),'lxml')\n",
    "        tables = soup.find_all('table', class_ = 'wikitable') # , class_=\"wikitable sortable jquer-tablesorter\")\n",
    "        movie_set_us = []\n",
    "        for table in tables:\n",
    "            films = table.find_all('i')\n",
    "            for film in films:\n",
    "                title = film.text\n",
    "                # print(title)\n",
    "                link = film.find_all('a', href=True, title = True)\n",
    "                if len(link)==0:\n",
    "                    continue\n",
    "                else:\n",
    "                    link = link[0]['href']\n",
    "                primary_list.append((year,film.text,link))\n",
    "\n",
    "        \n",
    "pickle.dump(primary_list,open( 'my_data_3/PRIMARY_LIST', \"wb\" ))\n",
    "len(primary_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1971, 'McCabe & Mrs. Miller', '/wiki/McCabe_%26_Mrs._Miller')"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "primary_list[4566]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Wikipedia API\n",
    "\n",
    "The API consists of a collection of functions for standardizing budget (to US million dollars) and prediceded genres so that final Dataframes are all consistent.\n",
    "\n",
    "The following functions are defined below:\n",
    "1. wikiapi_film(title, year): returns **intro** and **infobox** HTML from wikipedia page\n",
    "2. get_genre(intro): Scrapes the intro paragraph of the wikipedia page and identifies genres\n",
    "3. movie_info_dict(infobox): returns dictionary with all the information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WIKIPEDIA API Function\n",
    "\n",
    "# Define function fr obtaining movie data using Wikipedia API\n",
    "def wikiapi_film(title, year):   \n",
    "    '''\n",
    "    Takes in a title, award and year, and returns the html content of the wikipedia page wikipedia page\n",
    "    ''' \n",
    "    if len(title)==0 or len(str(year)) == 0:\n",
    "        return \n",
    "    \n",
    "    try:\n",
    "        return wikipedia.page(title)\n",
    "    except wikipedia.exceptions.DisambiguationError:\n",
    "        pass\n",
    "    except wikipedia.exceptions.PageError:\n",
    "        pass\n",
    "   \n",
    "    title_with_date = title + f' ({year}_film)'\n",
    "    try:\n",
    "        print(title_with_date)\n",
    "        return wikipedia.page(title_with_date)\n",
    "    except wikipedia.exceptions.DisambiguationError:\n",
    "        pass\n",
    "    except wikipedia.exceptions.PageError:\n",
    "        pass\n",
    "\n",
    "    title_without_date = title + ' (film)'\n",
    "    try:\n",
    "        print(title_without_date)\n",
    "        return wikipedia.page(title_without_date)\n",
    "        if page==None:\n",
    "            try:\n",
    "                return wikipedia.page(title)\n",
    "            except wikipedia.exceptions.PageError:\n",
    "                print(f\"Warning: The Wikipedia page for the title {title} could not be found without date \")\n",
    " \n",
    "    except wikipedia.exceptions.PageError:\n",
    "        print(f\"\\tThe Wikipedia page for the title {title} could not be found \")\n",
    "        return \n",
    "    \n",
    "    except wikipedia.exceptions.DisambiguationError:\n",
    "        print(f\"\\tThe Wikipedia page for the title {title} could not be found \")\n",
    "        return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the standardized genre specified in genre_dict file\n",
    "genre_dict = {\n",
    "        'romance': 'rom','romantic': 'rom','comedy': 'com','musical':'mus',\n",
    "        'animated':'ani','superhero':'sup','horror':'hor','crime': 'cri',\n",
    "        'war ':'war','psychological':'psy','psychology':'psy','action':'act',\n",
    "        'dystopian':'dys','political':'pol','spy':'spy','science': 'sci',\n",
    "        'adventure':'adv','fantasy': 'fan','biography': 'bio','biographical': 'bio',\n",
    "        'historical':'his','mystery':'mys','epic':'epi','thrill':'thr','drama':'dra',\n",
    "        'monster': 'mon','disaster':'dis','other':'oth'\n",
    "    }\n",
    "pickle.dump(genre_dict,open( 'my_data_3/genre_dict', \"wb\" ))\n",
    "len(genre_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genre(intro):\n",
    "    \"\"\"\n",
    "    returns the movie genre based on wikipedia intro\n",
    "    \"\"\"\n",
    "    genre_dict = pickle.load(open(\"my_data_3/genre_dict\",\"rb\"))\n",
    "    this_movie_genres = []\n",
    "    for line in intro: # got through all the lines\n",
    "        line = line.text.split('.')\n",
    "        line = line[0]\n",
    "        line = line.lower()\n",
    "        for genre in genre_dict:\n",
    "            if line.find(genre) > 0:\n",
    "                this_movie_genres.append(genre_dict[genre])\n",
    "        \n",
    "        if len(this_movie_genres)>0:\n",
    "            return list(set(this_movie_genres))\n",
    "    return 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary from Wikipedia page of the film using the INFOBOX table\n",
    "\n",
    "def movie_infobox_dict(infobox_items, intro):\n",
    "    # initialiZe empty dictionary\n",
    "    movie_dict = dict()\n",
    "    \n",
    "    # Go through each infobox item and extract information\n",
    "    for item in infobox_items:\n",
    "        try:\n",
    "            if len(item) < 2:\n",
    "                continue\n",
    "            \n",
    "            #director\n",
    "            if item.th.text.lower().find('direct')>-1:\n",
    "                movie_dict['director'] = []\n",
    "                if item.td.find('div', class_=\"plainlist\")==None: # single entries\n",
    "                    for line in item.td.find_all('a'):\n",
    "                        movie_dict['director'].append(line.text)      \n",
    "                else:\n",
    "                    for line in item.td.find('div', class_=\"plainlist\").find_all('li'):\n",
    "                        movie_dict['director'].append(line.text)\n",
    "                if len(movie_dict['director'])==0:\n",
    "                    movie_dict['director'] = item.td.text.split('br')\n",
    "            #producer\n",
    "            if item.th.text.lower().find('produce')>-1:\n",
    "                movie_dict['producer'] = []\n",
    "                if item.td.find('div', class_=\"plainlist\")==None: # single entries\n",
    "                    for line in item.td.find_all('a'):\n",
    "                        movie_dict['producer'].append(line.text)    \n",
    "                else:\n",
    "                    for line in item.td.find('div', class_=\"plainlist\").find_all('li'):\n",
    "                        movie_dict['producer'].append(line.text) \n",
    "                if len(movie_dict['producer'])==0:\n",
    "                    movie_dict['producer'] = item.td.text.split('br')\n",
    "\n",
    "            #cast\n",
    "            if item.th.text.lower().find('star')>-1:\n",
    "                movie_dict['cast'] = []\n",
    "                if item.td.find('div', class_=\"plainlist\")==None: # single entries\n",
    "                    for line in item.td.find_all('a'):\n",
    "                        movie_dict['cast'].append(line.text)\n",
    "                else:\n",
    "                    for line in item.td.find('div', class_=\"plainlist\").find_all('li'):\n",
    "                        movie_dict['cast'].append(line.text)\n",
    "                if len(movie_dict['cast'])==0:\n",
    "                    movie_dict['cast'] = item.td.text.split('br')\n",
    "\n",
    "            #screenplay\n",
    "            if item.th.text.lower().find('screenplay')>-1 or item.th.text.lower().find('written')>-1:\n",
    "                movie_dict['screenplay'] = []\n",
    "                if item.td.find('div', class_=\"plainlist\")==None: # single entries\n",
    "                    for line in item.td.find_all('a'):\n",
    "                        movie_dict['screenplay'].append(line.text)\n",
    "                else:\n",
    "                    for line in item.td.find('div', class_=\"plainlist\").find_all('li'):\n",
    "                        movie_dict['screenplay'].append(line.text)\n",
    "                if len(movie_dict['screenplay'])==0:\n",
    "                    movie_dict['screenplay'] = item.td.text.split('br')\n",
    "\n",
    "            #cinematography\n",
    "            if item.th.text.lower().find('cinematography')>-1:\n",
    "                movie_dict['cinematography'] = []\n",
    "                if item.td.find('div', class_=\"plainlist\")==None: # single entries\n",
    "                    for line in item.td.find_all('a'):\n",
    "                        movie_dict['cinematography'].append(line.text)\n",
    "                else:\n",
    "                    for line in item.td.find('div', class_=\"plainlist\").find_all('li'):\n",
    "                        movie_dict['cinematography'].append(line.text)\n",
    "                if len(movie_dict['cinematography'])==0:\n",
    "                    movie_dict['cinematography'] = item.td.text.split('br')\n",
    "\n",
    "            # music\n",
    "            if item.th.text.lower().find('music')>-1 or item.th.text.lower().find('score')>-1:\n",
    "                movie_dict['music'] = []\n",
    "                if item.td.find('div', class_=\"plainlist\")==None: # single entries\n",
    "                    for line in item.td.find_all('a'):\n",
    "                        movie_dict['music'].append(line.text)\n",
    "                else:\n",
    "                    for line in item.td.find('div', class_=\"plainlist\").find_all('li'):\n",
    "                        movie_dict['music'].append(line.text)\n",
    "                if len(movie_dict['music'])==0:\n",
    "                    movie_dict['music'] = item.td.text\n",
    "                \n",
    "            \n",
    "            # editing\n",
    "            if item.th.text.lower().find('edit')>-1:\n",
    "                movie_dict['edit'] = []\n",
    "                if item.td.find('div', class_=\"plainlist\")==None: # single entries\n",
    "                    for line in item.td.find_all('a'):\n",
    "                        movie_dict['edit'].append(line.text)\n",
    "                else:\n",
    "                    for line in item.td.find('div', class_=\"plainlist\").find_all('li'):\n",
    "                        movie_dict['edit'].append(line.text)\n",
    "                if len(movie_dict['edit'])==0:\n",
    "                    movie_dict['edit'] = item.td.text.split('br')\n",
    "\n",
    "\n",
    "            # Based on a book (Y/N)\n",
    "            if item.th.text.lower().find('based')>-1:\n",
    "                movie_dict['book'] = 'yes'\n",
    "\n",
    "            # Get budget\n",
    "            if item.th.text.lower().find('budget')>-1:\n",
    "                budget = item.td.text.strip()\n",
    "                budget = re.sub(r'\\[.+\\]+', \"\", budget) #remove square bracket references\n",
    "                movie_dict['budget'] = currency_to_million(budget)\n",
    "\n",
    "            # Get box office\n",
    "            if item.th.text.lower().find('box')>-1:\n",
    "                box_office = item.td.text.strip()\n",
    "                box_office = re.sub(r'\\[.+\\]+', \"\", box_office)#remove square bracket references\n",
    "                movie_dict['box_office'] = currency_to_million(box_office)\n",
    "\n",
    "            # Get running time\n",
    "            if item.th.text.lower().find('running time')>-1:\n",
    "                running_time = item.td.text.strip()\n",
    "                running_time = re.findall(r'(\\d+)\\smin', running_time)\n",
    "                if len(running_time)==0:\n",
    "                    movie_dict['running_time'] = 0\n",
    "                    continue\n",
    "                movie_dict['running_time'] = int(running_time[0])\n",
    "\n",
    "            # Language \n",
    "            if item.th.text.lower().find('language')>-1:\n",
    "                language = item.td.text.strip()\n",
    "                if (language.lower().find('english') == -1 and \n",
    "                    language.lower().find('silent') == -1): # film does not contain english\n",
    "                    return dict()\n",
    "                movie_dict['language']= language.split('\\n')\n",
    "\n",
    "            # Release date \n",
    "            \n",
    "            if item.th.text.lower().find('release')>-1:\n",
    "                release = item.td.text.strip()\n",
    "                release = re.findall(r'\\d\\d\\d\\d', release)\n",
    "                release = dt.datetime.strptime(release[0], '%Y').year\n",
    "                if len(str(release))==0:\n",
    "                    continue\n",
    "                movie_dict['year']=release\n",
    "            \n",
    "            \n",
    "            # Get genre\n",
    "            movie_dict['genre'] = get_genre(intro)\n",
    "\n",
    "        except AttributeError:\n",
    "            print(f'\\tCould not fetch info for {title} from infobox items')\n",
    "\n",
    "    return movie_dict\n",
    "\n",
    "\n",
    "# Converts different denominations to $X.y million\n",
    "def currency_to_million(money):\n",
    "    ''' Accepts $12 million and returns 12000000\n",
    "        Accepts $13,678,654 and reurns  13678654\n",
    "        using regular expressions\n",
    "    '''\n",
    "    if money == None:\n",
    "        return np.nan\n",
    "    if len(money)==0:\n",
    "        return np.nan\n",
    "\n",
    "    # Check to see dollar, otherwise return nan\n",
    "    money = money.lower()\n",
    "    if money.find('$')>-1:\n",
    "        factor=1\n",
    "    elif money.find('£')>-1:\n",
    "        factor = 1.3\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "    money = re.sub(r'\\[.*\\]', '', money) #remove square bracket citation\n",
    "\n",
    "    if money.find('illion')>0: # when currency expressed in million/billion\n",
    "\n",
    "        # Billion: $12.4 billion\n",
    "        reg = r\"[\\$-–]([0-9.]+)\\sbillion\"\n",
    "        num = re.findall(reg, money) # find number like $12.4 billion\n",
    "        if len(num)>0:\n",
    "            # num = re.sub(r'\\D', \"\", num) # drop any non-numeric characters like comma, dash etc\n",
    "            return  round(float(num[0])*1e3*factor,2)\n",
    "\n",
    "        # Million: $6.8 million\n",
    "        reg = r\"[\\$-–]([0-9.]+)\\smillion\"\n",
    "        num = re.findall(reg, money) # find number like $6.8 million\n",
    "        if len(num)>0:\n",
    "            # num = re.sub(r'\\D', \"\", num) # drop any non-numeric characters like comma, dash etc\n",
    "            try:\n",
    "                return round(float(num[0])*factor,2)\n",
    "            except:\n",
    "                return np.nan\n",
    "\n",
    "    else: # When currency not expressed in millions  \n",
    "        reg = r\"[$£]\\s?([\\d,]+)[\\D\\s]?\"\n",
    "        num = re.findall(reg, money)\n",
    "        if len(num) >0:\n",
    "            num = re.sub(r',', '', num[0])\n",
    "            try:\n",
    "                return round(float(num)/1e6*factor,2)\n",
    "            except:\n",
    "                return np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the main function that calls wikiapi_film, OMDB API and ancillary functions to get the dictionaries\n",
    "def get_all_movie_info(title, year):\n",
    "    \n",
    "    # Now wikipedia info\n",
    "    page = wikiapi_film(title, year)\n",
    "    if page == None:\n",
    "        return dict()\n",
    "\n",
    "    soup = BeautifulSoup(page.html(),'html5lib') \n",
    "    \n",
    "    # Get wikipedia introduction paragraph for genres\n",
    "    try:\n",
    "        intro = soup.find_all('p')\n",
    "    except:\n",
    "        print(f'Could not find p-tags info for {title}')\n",
    "        return dict()\n",
    "    \n",
    "    # Get wikipedia infobox tables for all other information\n",
    "    try:\n",
    "        infobox_items = soup.find('table', class_ = 'infobox vevent').tbody.find_all('tr')\n",
    "    except: \n",
    "        print(f'Could not find infobox for {title}')\n",
    "        return dict()\n",
    "        \n",
    "    this_dict = movie_infobox_dict(infobox_items, intro)\n",
    "#     this_genre = get_genre(intro, genre_dict)\n",
    "#     this_dict['genre'] = this_genre\n",
    "\n",
    "    # obtain json file from OMDB API and get info\n",
    "    url_base = 'http://www.omdbapi.com/?i=tt3896198&apikey=5db77b44&'\n",
    "    url = url_base + 't=' + str(title)\n",
    "    r = requests.get(url)\n",
    "    json_data = r.json()\n",
    "    if 'Error' in json_data:\n",
    "        print(f'\\t{title} not found in OMDB API')\n",
    "        return dict()\n",
    "    try:\n",
    "        this_dict['imdbID'] = json_data['imdbID']\n",
    "        this_dict['imdb_rating'] = float(json_data['imdbRating'])\n",
    "        this_dict['n_votes'] = int(re.sub(r',','',json_data['imdbVotes']))\n",
    "        this_dict['title'] =title\n",
    "    except:\n",
    "        return dict()\n",
    "    \n",
    "    return this_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5886, 10)\n",
      "0 of 5886\n",
      "Could not find infobox for extreme prejudice\n",
      "Could not find infobox for x-men\n",
      "Could not find infobox for x\n",
      "Could not find infobox for pirates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ranitsengupta/opt/anaconda3/lib/python3.7/site-packages/wikipedia/wikipedia.py:389: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file /Users/ranitsengupta/opt/anaconda3/lib/python3.7/site-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the impossible (2012_film)\n",
      "Could not find infobox for split(ix) \n",
      "Could not find infobox for twilight\n",
      "Could not find infobox for the lord of the rings\n",
      "Could not find infobox for titanic\n",
      "Could not find infobox for men in black\n"
     ]
    }
   ],
   "source": [
    "# Get movie_dict and SAVE\n",
    "df_imdb = pd.read_csv('my_data_3/df_imdb.csv')\n",
    "df_imdb.reset_index()\n",
    "print(df_imdb.shape)\n",
    "movie_dict = dict()\n",
    "for row in df_imdb.iterrows():\n",
    "    if row[0]%50==0:\n",
    "        print(f'{row[0]} of {len(df_imdb)}')\n",
    "    title = row[1].title.lower()\n",
    "    year = row[1].year\n",
    "    movie_dict[title] = get_all_movie_info(title, year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe_from_dict(movie_dict, all_columns):\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    rejects = []\n",
    "    for i,title in enumerate(movie_dict):\n",
    "        \n",
    "        movie = movie_dict[title]\n",
    "        if len(movie)==0:\n",
    "            print(f'\\tCould not prepare DataFrame for {title}. Movie info missing!')\n",
    "            continue\n",
    "            \n",
    "        for col in all_columns:\n",
    "            # print(i,title)\n",
    "            if col in movie:\n",
    "                if type(movie[col])!=list:\n",
    "                    df.loc[i,col] = movie[col]\n",
    "                elif type(movie[col])==list:\n",
    "                    df.loc[i,col] = len(movie[col])\n",
    "            else:\n",
    "                rejects.append(title)\n",
    "\n",
    "\n",
    "    return df, list(set(rejects))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'movie_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-56e55948c1ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create DataFrame and SAVE as df_movies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'imdbID'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'year'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'n_votes'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'imdb_rating'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'budget'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'box_office'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'cast'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'running_time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf_movies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrejected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_dataframe_from_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovie_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdf_movies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_movies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'movie_dict' is not defined"
     ]
    }
   ],
   "source": [
    "# Create DataFrame and SAVE as df_movies\n",
    "columns = ['imdbID','title','year','n_votes','imdb_rating','budget', 'box_office','cast','running_time']\n",
    "df_movies, rejected = create_dataframe_from_dict(movie_dict, columns)\n",
    "df_movies = df_movies.dropna()\n",
    "print('Done!')\n",
    "\n",
    "# Convert year column from integer to date_time\n",
    "yr_column = pd.to_datetime(df_movies.year.astype('int'), format='%Y')\n",
    "df_movies.year = [y.year for y in yr_column]\n",
    "df_movies.head()\n",
    "df_movies.to_csv('my_data_3/df_movies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get movie info for all movies in PRIMARY LIST and save it in primary_movie_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Data Acquisition for Academy Awards with Webscraping and API\n",
    "<a id=\"acquisition\"></a>\n",
    "\n",
    "We will use BeautifulSoup for web-scraping together with the wikipedia API to obtain information about the most popular films released between 1960 and 2019 and the various Academy Awards nominations and wins during that period. Out goal is to look at hollywood films under three categories of performance: awards, critical review and revenue to identify what predicts the success of a movie. \n",
    "\n",
    "In other words, we see each film in terms of its measurable and identifiable features and see hwo they contributed to the success of a movie. Are big budget movies more likely to win awards? Is it the size or profile of the cast size that are likely to draw a more critically acclaim? Are longer movies more popular among the award committe and the fans alike?\n",
    "\n",
    "In order to obtain clean and reliable movie information and their awards and nomination in the different film categories, we use two APIs: the wikiedpa API and the omdb API. \n",
    "\n",
    "We also use the BeautifulSoup module aloing with regular expressions (re) to extract the various information from wikipedia and IMDB to obtain the most reliable information about films. \n",
    "\n",
    "## 2.2 Web scraping from Wikipedia\n",
    "\n",
    "The following function obtained information about a film, namely its director, cast, running time, budget and box office information as shown below for Lawrence of Arabia (1962), which was used for predicting the Oscars for 2020. \n",
    "The information is returned as a Python dictionary.\n",
    "<br>\n",
    "<img src=\"files/wiki4.png\" height=\"100\" width=\"100\" align=\"left\" style=\"width:40%\">\n",
    "<img src=\"files/wiki2.png\" height=\"100\" width=\"100\" align=\"center\" style=\"width:40%\">\n",
    "\n",
    "\n",
    "## 2.1 The Wikipedia API\n",
    "The following function accepts a title, year or category and obtains the HTML document for the relevant wikipedia page. \n",
    "\n",
    "The wikpedia pages for the Academy Awars expect get request not in the specification of year (eg. 1974 Academy Awards), but in the form of \"N<sup>th</sup> Academy Awards, such as <a href=\"https://en.wikipedia.org/wiki/34th_Academy_Awards\">\"34th Academy Awards\"</a>\". The same wikipedia API can can individual film information if movie and year are specified, and The Academy Awards information for a given year as shwon below.\n",
    "<br>\n",
    "\n",
    "#### Getting Oscar Editions\n",
    "The Wikipedia page for The Academy Awards is referenced **not** by the year (eg. 1962 Academy Awards) but by its edition (34th Academy Awards) as shown below. \n",
    "<br>\n",
    "<img src=\"files/wiki.jpeg\" height=\"800\" width=\"800\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Wikipedia pages for Academy Awards are listed in terms of their edition: 1st, 2nd, 3rd, etc.\n",
    "\n",
    "\n",
    "def wikiapi_nth(year, award = ' Academy Awards'):\n",
    "    year =get_edition(year)\n",
    "    year_award_wikiformat = year + award\n",
    "    try:\n",
    "        return wikipedia.page(year_award_wikiformat)\n",
    "    except wikipedia.exceptions.PageError:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        return wikipedia.page(year_award_wikiformat.replace(' ','_'))\n",
    "    except wikipedia.exceptions.PageError:\n",
    "        print(f\"The page for the year {year_award_wikiformat} could not be found \")\n",
    "        return\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_edition(year):\n",
    "    '''Takes in a year and returns the edition of the given year's oscars\n",
    "    eg: Academy Awards, 1930 and returns 2nd Academy Awards'''\n",
    "    \n",
    "    # Define editiona\n",
    "    editions = ['th','st', 'nd', 'rd','th', 'th', 'th', 'th', 'th', 'th', 'th']\n",
    "    # editions_dict = {}\n",
    "    nth = year - 1928\n",
    "    if nth>10 and nth<20:\n",
    "        year_th = str(nth)+'th'\n",
    "    else:\n",
    "        year_th = str(nth) + editions[nth%10]\n",
    "    return year_th\n",
    "\n",
    "\n",
    "# Get the standardized genre specified in genre_dict file\n",
    "def get_genre(intro):\n",
    "    \"\"\"Takes in the intro paragraph from Wikipedia and scrapes out information about genre\n",
    "    \"\"\"\n",
    "    genre_dict = pickle.load(open(\"my_data_2/genre_dict\",\"rb\"))\n",
    "    this_movie_genres = []\n",
    "    for line in intro: # got through all the lines\n",
    "        line = line.text.split('.')\n",
    "        line = line[0]\n",
    "        line = line.lower()\n",
    "        for genre in genre_dict:\n",
    "            if line.find(genre) > 0:\n",
    "                this_movie_genres.append(genre_dict[genre])\n",
    "        \n",
    "        if len(this_movie_genres)>0:\n",
    "            return list(set(this_movie_genres))\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediceded list of award categories\n",
    "main_categories = ['picture','director','s_actor','s_actress','actor', \n",
    "                   'actress','screenplay','music','cinematography',\n",
    "                   'editing','effects','sound','costume', \n",
    "                   'song', 'art_direction']\n",
    "pickle.dump(main_categories,open( 'my_data_3/main_categories', \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['picture', 'director', 's_actor', 's_actress', 'actor', 'actress', 'screenplay', 'music', 'cinematography', 'editing', 'effects', 'sound', 'costume', 'song', 'art_direction']\n"
     ]
    }
   ],
   "source": [
    "print(main_categories)\n",
    "def get_main_category(category):\n",
    "    category = category.lower()\n",
    "\n",
    "    if category.find('story')>=0:\n",
    "        return 'other'\n",
    "    if category.find('best picture')>=0 or category.find('best motion picture')>=0:\n",
    "        return 'picture'\n",
    "    if category.find('outstanding production')>=0 or category.find('outstanding picture')>=0:\n",
    "        return 'picture'\n",
    "    if category.find('actor')>=0:\n",
    "        if category.find('supporting')>=0:\n",
    "            return 's_actor'\n",
    "        else:\n",
    "            return 'actor'   \n",
    "    if category.find('actress')>=0:\n",
    "        if category.find('supporting')>=0:\n",
    "            return 's_actress'\n",
    "        else:\n",
    "            return 'actress'    \n",
    "    if category.find('best director')>=0:\n",
    "        return 'director'\n",
    "    if category.find('screenplay')>=0:\n",
    "        return 'screenplay'\n",
    "    if category.find('music')>=0 or (category.find('scor')>=0):\n",
    "        return 'music'\n",
    "    if category.find('costume')>=0:\n",
    "        return 'costume'\n",
    "    if category.find('editing')>=0:\n",
    "        return 'editing'\n",
    "    if category.find('effects')>=0:\n",
    "        return 'effects'\n",
    "    if category.find('cinematography')>=0:\n",
    "        return 'cinematography'\n",
    "    if category.find('sound')>=0:\n",
    "        return 'sound'\n",
    "    if category.find('song')>=0:\n",
    "        return 'song'\n",
    "    if category.find('art')>=0 and category.find('direct')>=0:\n",
    "        return 'art_direction'\n",
    "    # if category.find('art direction')>=0:\n",
    "        # return 'art direction'\n",
    "    else:\n",
    "        # print(f'Warning:{category} did not get matched!')\n",
    "        return 'other'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Awards and Nominations\n",
    "def awards_and_nominations(year, award = ' Academy Awards', all_categories = 'all'):\n",
    "    '''\n",
    "    This function accepts year, title or award and goes into the wikipedia page of the Award \n",
    "    or the Movie and extrac t all the necessary information.\n",
    "    '''\n",
    "    \n",
    "    if all_categories=='all':\n",
    "        all_categories = pickle.load(open(\"my_data_3/main_categories\",\"rb\")) \n",
    "\n",
    "    \n",
    "    # initialize empty DataFrame and the corresponding Screening Number\n",
    "    oscars_wn = pd.DataFrame()\n",
    "    missing_categories = []\n",
    "    winner_list = dict()\n",
    "    nominee_list = dict()\n",
    "    \n",
    "    # Get the html file from the Wikipedia page using the wikipedia API.\n",
    "    # Parse it with BeautifulSoup\n",
    "    page = wikiapi_nth(year)\n",
    "    soup = BeautifulSoup(page.html(),'lxml')\n",
    "    print(get_edition(year))\n",
    "        \n",
    "    # Get the table-body (tbody) from the wikipedia page where Oscars information are stored\n",
    "    tbody = soup.body.find('table', class_=\"wikitable\").find('tbody')\n",
    "       \n",
    "    # Make sure number of cells and header match\n",
    "    if len(tbody.find_all('td')) !=len(tbody.find_all(['div', 'th'])):\n",
    "    \n",
    "        # The wikipedia tables needs to be fixed! Some category header may be missing.\n",
    "        print('Warning: Number of cell <td> element  and header <th> does not add up for year:', year)\n",
    "        print('Returned Empty dataFrame')\n",
    "        return oscars_wn, missing_categories\n",
    "        \n",
    "        \n",
    "    # Get winners and nominees\n",
    "    try:\n",
    "        for td,th in zip(tbody.find_all('td'),tbody.find_all(['div', 'th'])):\n",
    "            cat = th.text.strip()\n",
    "            # Get standardized categories\n",
    "            category = get_main_category(cat)\n",
    "            if category not in all_categories:\n",
    "                continue\n",
    "            winner_list[category] = [] # inditialize an empty dictionary\n",
    "            nominee_list[category] = []\n",
    "\n",
    "            if category=='other':\n",
    "                missing_categories.append(cat)\n",
    "                # print(f'Warning in {category} in {year}')\n",
    "\n",
    "            # Go into the list and look at every line\n",
    "            for tli in td.find_all('li'):\n",
    "                # go down each line (li) and check if it is bolded\n",
    "                if tli.find('b')!= None: # winner\n",
    "                    winner = tli.find('i').text.strip()       # get italicized movie\n",
    "                    winner = re.sub(r'–',\"\", winner).strip()\n",
    "                    winner = winner.lower()\n",
    "                    winner_list[category].append(winner) # add movie to winner list\n",
    "                    oscars_wn.loc[winner,'year']= int(year)-1\n",
    "                    oscars_wn.loc[winner,category]='W'\n",
    "                    \n",
    "                elif tli.find('b')== None: #nominee\n",
    "                    nominee = tli.find('i').text.strip()      # get italicized movie\n",
    "                    nominee = re.sub(r'–',\"\", nominee).strip()\n",
    "                    nominee = nominee.lower()\n",
    "                    nominee_list[category].append(nominee)\n",
    "                    oscars_wn.loc[nominee,'year']= int(year)-1\n",
    "                    if nominee in winner_list[category]: # if same movie has already won, leave it unchanged as 'W'\n",
    "                        oscars_wn.loc[nominee,category]='WN'\n",
    "                    else:\n",
    "                        oscars_wn.loc[nominee,category]='N'\n",
    "\n",
    "        \n",
    "    except AttributeError:\n",
    "        print(f'Warning: in Category {category} for Year: {year}')\n",
    "            \n",
    "\n",
    "    # oscars_wn['film'] = oscars_wn.index\n",
    "    return oscars_wn.fillna('O'), missing_categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In year 1950\n",
      "22nd\n",
      "23rd\n",
      "24th\n",
      "25th\n",
      "26th\n",
      "27th\n",
      "28th\n",
      "29th\n",
      "30th\n",
      "31st\n",
      "In year 1960\n",
      "32nd\n",
      "33rd\n",
      "34th\n",
      "35th\n",
      "36th\n",
      "37th\n",
      "38th\n",
      "39th\n",
      "40th\n",
      "41st\n",
      "In year 1970\n",
      "42nd\n",
      "43rd\n",
      "44th\n",
      "45th\n",
      "46th\n",
      "47th\n",
      "48th\n",
      "49th\n",
      "50th\n",
      "51st\n",
      "In year 1980\n",
      "52nd\n",
      "53rd\n",
      "54th\n",
      "55th\n",
      "56th\n",
      "57th\n",
      "58th\n",
      "59th\n",
      "60th\n",
      "61st\n",
      "In year 1990\n",
      "62nd\n",
      "63rd\n",
      "64th\n",
      "65th\n",
      "66th\n",
      "67th\n",
      "68th\n",
      "69th\n",
      "70th\n",
      "71st\n",
      "In year 2000\n",
      "72nd\n",
      "73rd\n",
      "74th\n",
      "75th\n",
      "76th\n",
      "77th\n",
      "78th\n",
      "79th\n",
      "80th\n",
      "81st\n",
      "In year 2010\n",
      "82nd\n",
      "83rd\n",
      "84th\n",
      "85th\n",
      "86th\n",
      "87th\n",
      "88th\n",
      "89th\n",
      "90th\n",
      "91st\n"
     ]
    }
   ],
   "source": [
    "# GET MOVIE AWARDS FROM ALL CATEGORIES\n",
    "df_oscars = pd.DataFrame()\n",
    "for year in range(1950,2020):\n",
    "    if year%10==0:\n",
    "        print(f'In year {year}')\n",
    "    df, missing = awards_and_nominations(year)\n",
    "    df_oscars = df_oscars.append(df)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oscars.year = df_oscars.year.astype('int').astype('str')\n",
    "x = pd.to_datetime(df_oscars.year, format='%Y', exact=True)\n",
    "df_oscars.year = [x.year for x in pd.to_datetime(df_oscars.year, format='%Y', exact=True)]\n",
    "df_oscars = df_oscars.fillna('O')\n",
    "df_oscars.to_csv('my_data_3/df_oscars_films.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Awards and Nominations for individuals: actor, actress, director\n",
    "def individual_awards_and_nominations(year, get_categories ='all', award =' Academy Awards'):\n",
    "    '''\n",
    "    This function accepts year, title or award and goes into the wikipedia page of the Award \n",
    "    or the Movie and extracts all the necessary information.\n",
    "    '''\n",
    "    \n",
    "    if get_categories == 'all':\n",
    "        get_categories = pickle.load(open(\"my_data_3/main_categories\",\"rb\"))\n",
    "\n",
    "    \n",
    "    # initialize empty DataFrame and the corresponding Screening Number\n",
    "    individual_wn = pd.DataFrame()\n",
    "    missing_categories = []\n",
    "    idx = 0\n",
    "    \n",
    "    # Get the html file from the Wikipedia page using the wikipedia API.\n",
    "    # Parse it with BeautifulSoup\n",
    "    page = wikiapi_nth(year)\n",
    "    soup = BeautifulSoup(page.html(),'lxml')\n",
    "        \n",
    "    # Get the table-body (tbody) from the wikipedia page where Oscars information are stored\n",
    "    tbody = soup.body.find('table', class_=\"wikitable\").find('tbody')\n",
    "       \n",
    "    # Make sure number of cells and header match\n",
    "    if len(tbody.find_all('td')) !=len(tbody.find_all(['div', 'th'])):\n",
    "    \n",
    "        # The wikipedia tables needs to be fixed! Some category header may be missing.\n",
    "        print('Warning: Number of cell <td> element  and header <th> does not add up for year:', year)\n",
    "        print('Returned Empty dataFrame')\n",
    "        return individual_wn, missing_categories\n",
    "        \n",
    "        \n",
    "    # Get winners and nominees\n",
    "    try:\n",
    "        for td,th in zip(tbody.find_all('td'),tbody.find_all(['div', 'th'])):\n",
    "            cat = th.text.strip()\n",
    "            category = get_main_category(cat)\n",
    "            # print('\\nCategory:', category)\n",
    "            if category not in get_categories:\n",
    "                # print(year, category)\n",
    "                continue\n",
    "\n",
    "            # Go into the list and remove the film names in <i> italic tags\n",
    "            for line in td.find_all('li'):\n",
    "                if line.find('i') != None:\n",
    "                    line.i.decompose() # remove film\n",
    "                    \n",
    "                if line.find('b')!= None: # if in bold then winner\n",
    "                    for wins in line.find_all('b'):\n",
    "                        if wins.find('i') != None: # remove film\n",
    "                            wins.i.decompose()\n",
    "                            \n",
    "                        if wins.find('a')!=None: # winner will be the first hyperlink\n",
    "                            winner = wins.find_all('a')[0].text.strip()\n",
    "                        else:\n",
    "                            winner = wins.text.strip() #if no hyperlink, winner is first text\n",
    "                        winner = re.sub(r'–',\"\", winner).strip()\n",
    "                        if winner != None:\n",
    "                            individual_wn.loc[idx,'year']= int(year)\n",
    "                            individual_wn.loc[idx, 'name']= winner\n",
    "                            individual_wn.loc[idx, 'category']= category\n",
    "                            individual_wn.loc[idx, 'result']= 'W'\n",
    "                            idx = idx + 1\n",
    "                \n",
    "                elif line.find('b') == None: # if no bold then not a winner\n",
    "                    if line.find('a') != None:\n",
    "                        nominee = line.find_all('a')[0].text.strip()\n",
    "                    else:\n",
    "                        nominee = line.text.strip()\n",
    "                    nominee = re.sub(r'–',\"\", nominee).strip()\n",
    "                    if nominee != None:\n",
    "                        individual_wn.loc[idx,'year']= int(year)\n",
    "                        individual_wn.loc[idx, 'name']= nominee\n",
    "                        individual_wn.loc[idx, 'category']= category\n",
    "                        individual_wn.loc[idx, 'result']= 'N'\n",
    "                        idx = idx + 1\n",
    "\n",
    "        \n",
    "    except AttributeError:\n",
    "        print(f'Warning: in Category {category} for Year: {year}')\n",
    "\n",
    "    return individual_wn, missing_categories\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In year 1950\n",
      "In year 1960\n",
      "In year 1970\n",
      "In year 1980\n",
      "In year 1990\n",
      "In year 2000\n",
      "In year 2010\n"
     ]
    }
   ],
   "source": [
    "# GET INDIVIDUAL AWARDS FROM ALL CATEGORIES\n",
    "get_categories = 'all'\n",
    "df_individual = pd.DataFrame()\n",
    "for year in range(1945,2020):\n",
    "    if year%10==0:\n",
    "        print(f'In year {year}')\n",
    "    df, missing = individual_awards_and_nominations(year)\n",
    "    df_individual = df_individual.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>Alejandro G. Iñárritu</td>\n",
       "      <td>director</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>Adam McKay</td>\n",
       "      <td>director</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>George Miller</td>\n",
       "      <td>director</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>Lenny Abrahamson</td>\n",
       "      <td>director</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>Tom McCarthy</td>\n",
       "      <td>director</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      year                   name  category result\n",
       "8   2016.0  Alejandro G. Iñárritu  director      W\n",
       "9   2016.0             Adam McKay  director      N\n",
       "10  2016.0          George Miller  director      N\n",
       "11  2016.0       Lenny Abrahamson  director      N\n",
       "12  2016.0           Tom McCarthy  director      N"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_individual.tail(20)\n",
    "df_individual.query(\"year == 2016\").query(\"category == 'director'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year                          name category result\n",
      "0  1945                   Leo McCarey  picture      W\n",
      "1  1945  Joseph Sistrom for Paramount  picture      N\n",
      "2  1945           Arthur Hornblow Jr.  picture      N\n",
      "3  1945             David O. Selznick  picture      N\n",
      "4  1945              Darryl F. Zanuck  picture      N\n"
     ]
    }
   ],
   "source": [
    "df_individual.year = df_individual.year.astype('int').astype('str')\n",
    "x = pd.to_datetime(df_individual.year, format='%Y', exact=True)\n",
    "df_individual.year = [x.year for x in pd.to_datetime(df_individual.year, format='%Y', exact=True)]\n",
    "print(df_individual.head())\n",
    "df_individual.to_csv('my_data_3/df_oscars_individual.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing IMDB DataFRame old fashioned way\n",
    "This approach will be discarded. The DataFrame is being constrcuted directly from movie_dict in Exploratory Data Analysis and saved as df_movie in my_data_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5886, 9)\n",
      "df_0_5887\n",
      "movie_dict_0_5887\n",
      "reject_0_5887\n",
      "(5886, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdbID</th>\n",
       "      <th>budget</th>\n",
       "      <th>cast_size</th>\n",
       "      <th>gross</th>\n",
       "      <th>imdb_rating</th>\n",
       "      <th>n_votes</th>\n",
       "      <th>runtime</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5881</td>\n",
       "      <td>tt2737050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.3</td>\n",
       "      <td>41876</td>\n",
       "      <td>95.0</td>\n",
       "      <td>two days, one night</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5882</td>\n",
       "      <td>tt0816442</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3</td>\n",
       "      <td>76.600000</td>\n",
       "      <td>7.6</td>\n",
       "      <td>120583</td>\n",
       "      <td>130.0</td>\n",
       "      <td>the book thief</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5883</td>\n",
       "      <td>tt1781769</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>68.929150</td>\n",
       "      <td>6.6</td>\n",
       "      <td>86498</td>\n",
       "      <td>130.0</td>\n",
       "      <td>anna karenina</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5884</td>\n",
       "      <td>tt1655442</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2</td>\n",
       "      <td>133.400000</td>\n",
       "      <td>7.9</td>\n",
       "      <td>219627</td>\n",
       "      <td>100.0</td>\n",
       "      <td>the artist</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5885</td>\n",
       "      <td>tt0090223</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>8.402424</td>\n",
       "      <td>6.5</td>\n",
       "      <td>829</td>\n",
       "      <td>111.0</td>\n",
       "      <td>twice in a lifetime</td>\n",
       "      <td>1985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         imdbID  budget  cast_size       gross  imdb_rating  n_votes  runtime  \\\n",
       "5881  tt2737050     0.0          4    0.000000          7.3    41876     95.0   \n",
       "5882  tt0816442    19.0          3   76.600000          7.6   120583    130.0   \n",
       "5883  tt1781769     NaN         11   68.929150          6.6    86498    130.0   \n",
       "5884  tt1655442    15.0          2  133.400000          7.9   219627    100.0   \n",
       "5885  tt0090223     NaN          6    8.402424          6.5      829    111.0   \n",
       "\n",
       "                    title  year  \n",
       "5881  two days, one night  2014  \n",
       "5882       the book thief  2013  \n",
       "5883        anna karenina  2012  \n",
       "5884           the artist  2011  \n",
       "5885  twice in a lifetime  1985  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the old movie datatset\n",
    "df_imdb = pd.read_csv('my_data_2/df_imdb.csv', index_col=[0])\n",
    "print(df_imdb.shape) #check shape\n",
    "\n",
    "# Define empti ditinary\n",
    "new_movie_dict = dict() # save movie information here including genre\n",
    "reject = []\n",
    "\n",
    "start = 0\n",
    "stop = 5887\n",
    "\n",
    "# filename strings\n",
    "strlim = str(start)+'_'+str(stop)\n",
    "dstr = 'df_'+ strlim\n",
    "mstr = 'movie_dict_' + strlim\n",
    "rstr = 'reject_' + strlim\n",
    "print(dstr)\n",
    "print(mstr)\n",
    "print(rstr)\n",
    "\n",
    "df_imdb = df_imdb.iloc[start:stop,:]\n",
    "print(df_imdb.shape)\n",
    "df_imdb.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
